{
  "common": {
    "loading": "加载中...",
    "error": "错误",
    "success": "成功",
    "save": "保存",
    "cancel": "取消",
    "delete": "删除",
    "edit": "编辑",
    "create": "创建",
    "search": "搜索",
    "refresh": "刷新",
    "confirm": "确认",
    "back": "返回",
    "submit": "提交",
    "reset": "重置",
    "close": "关闭",
    "open": "打开",
    "status": "状态",
    "actions": "操作",
    "details": "详情",
    "description": "描述",
    "name": "名称",
    "name_placeholder": "仅支持英文和数字",
    "type": "类型",
    "created_at": "创建时间",
    "updated_at": "更新时间",
    "join_wechat": "加入微信群",
    "join_discord": "加入Discord",
    "view_github": "在GitHub上查看",
    "view_docs": "查看文档",
    "switch_theme": "切换到{{theme}}模式",
    "light": "浅色",
    "dark": "深色",
    "toggle_sidebar": "切换侧边栏",
    "switch_language": "切换语言",
    "scan_qrcode": "扫描二维码添加微信",
    "add_wechat_note": "备注：unla或mcpgw",
    "next": "下一步",
    "filter": "筛选",
    "more": "更多",
    "less": "收起",
    "all": "全部",
    "none": "无",
    "yes": "是",
    "no": "否",
    "ok": "确定",
    "retry": "重试",
    "upload": "上传",
    "download": "下载",
    "preview": "预览",
    "settings": "设置",
    "profile": "个人资料",
    "help": "帮助",
    "about": "关于",
    "contact": "联系我们",
    "feedback": "反馈",
    "report": "报告",
    "join_wechat_community": "加入微信社区",
    "join_discord_community": "加入Discord社区",
    "switch_theme_theme": "切换到{{theme}}主题",
    "no_results": "未找到结果",
    "copy": "复制",
    "copied": "已复制: {{text}}",
    "copy_failed": "复制失败",
    "add": "添加",
    "clear": "清除",
    "collapse": "收起",
    "expand": "展开",
    "already": "已",
    "available": "可用",
    "sse_url": "SSE URL",
    "streamable_http_url": "Streamable HTTP URL",
    "total_items": "共 {{total}} 条",
    "experimental": "实验性"
  },
  "nav": {
    "dashboard": "仪表盘",
    "settings": "设置",
    "profile": "个人资料",
    "gateway": "网关配置",
    "chat": "聊天对话",
    "users": "用户管理",
    "tenants": "租户管理",
    "tools_config": "工具配置",
    "sse_url": "SSE URL",
    "streamable_http_url": "Streamable HTTP URL",
    "config_versions": "配置历史",
    "llm": "模型配置",
    "groups": {
      "chat_ai": "聊天与AI",
      "gateway_config": "网关与配置",
      "management": "管理"
    }
  },
  "auth": {
    "login": "登录",
    "logout": "退出",
    "register": "注册",
    "forgot_password": "忘记密码",
    "reset_password": "重置密码",
    "change_password": "修改密码",
    "current_password": "当前密码",
    "new_password": "新密码",
    "confirm_password": "确认密码",
    "current_password_placeholder": "请输入当前密码",
    "new_password_placeholder": "请输入新密码",
    "confirm_password_placeholder": "请确认新密码",
    "password_mismatch": "两次输入的密码不一致",
    "password_change_success": "密码修改成功",
    "password_change_failed": "密码修改失败，请重试",
    "confirm_change": "确认修改",
    "username": "用户名",
    "password": "密码",
    "username_placeholder": "请输入用户名",
    "password_placeholder": "请输入密码",
    "login_to_continue": "请登录以继续",
    "login_success": "登录成功",
    "login_failed": "登录失败，请重试",
    "logout_success": "退出成功",
    "session_expired": "会话已过期，请重新登录",
    "or_continue_with": "或继续使用",
    "continue_with_google": "使用 Google 继续",
    "continue_with_github": "使用 GitHub 继续",
    "oauth_login_failed": "OAuth 登录失败"
  },
  "gateway": {
    "title": "网关管理",
    "add": "创建",
    "edit": "编辑",
    "delete": "删除",
    "export": "导出",
    "sync": "同步",
    "import_openapi": "导入 OpenAPI",
    "edit_config": "编辑 MCP 服务配置",
    "add_config": "添加新的 MCP 服务配置",
    "routing_config": "路由配置",
    "enabled_tools": "已启用的工具",
    "all_tools": "所有工具",
    "mcp_config": "MCP 配置",
    "backend_config": "MCP URL",
    "add_success": "网关创建成功",
    "add_failed": "网关创建失败",
    "edit_success": "配置保存成功",
    "edit_failed": "配置保存失败",
    "delete_success": "网关删除成功",
    "delete_failed": "网关删除失败",
    "exporting": "正在导出...",
    "export_success": "导出成功",
    "export_failed": "导出失败",
    "sync_success": "配置同步成功",
    "sync_failed": "配置同步失败",
    "import_success": "OpenAPI 规范导入成功",
    "import_failed": "OpenAPI 规范导入失败",
    "select_tenant": "选择租户",
    "search_tenant": "搜索租户...",
    "view_mode": "视图模式",
    "card_view": "卡片视图",
    "table_view": "表格视图",
    "name": "名称",
    "name_locked": "名称创建后不可修改",
    "description": "描述",
    "routing": "路由",
    "no_description": "暂无描述",
    "routes": "个路由",
    "backends": "个后端",
    "enabled": "已启用",
    "total": "总共",
    "yaml_mode": "YAML 模式",
    "form_mode": "表单模式",
    "tenant": "租户",
    "created_at": "创建时间",
    "updated_at": "更新时间",
    "proxy_type": "代理类型",
    "router_config": "路由配置",
    "prefix": "前缀",
    "server": "服务",
    "server_config": "服务配置",
    "server_name": "服务名称",
    "namespace": "命名空间",
    "allowed_tools": "允许的工具",
    "add_tool": "添加工具",
    "tools_config": "工具配置",
    "tool_name": "工具名称",
    "method": "请求方法",
    "endpoint": "接口地址",
    "mcp_server_config": "MCP 服务配置",
    "mcp_type": "MCP 类型",
    "command": "命令",
    "args": "参数",
    "env_variables": "环境变量",
    "url": "URL",
    "http_method": "HTTP 方法",
    "add_server": "添加服务",
    "startup_policy": "启动策略",
    "policy_on_demand": "按需连接",
    "policy_on_start": "启动时连接",
    "preinstalled": "当MCP Gateway服务启动时预安装MCP Server",
    "arguments_config": "参数配置",
    "argument_name": "参数名称",
    "argument_position": "位置",
    "argument_type": "类型",
    "argument_required": "必填",
    "argument_description": "描述",
    "argument_default": "默认值",
    "add_argument": "添加参数",
    "position_body": "请求体",
    "position_query": "查询参数",
    "position_path": "路径参数",
    "type_string": "字符串",
    "type_number": "数字",
    "type_boolean": "布尔值",
    "type_array": "数组",
    "type_object": "对象",
    "type_form_data": "表单数据",
    "enable_cors": "启用跨域(CORS)",
    "enable_auth": "启用认证",
    "auth_mode": "认证方式",
    "allow_origins": "允许的源",
    "allow_methods": "允许的方法",
    "allow_headers": "允许的头部",
    "expose_headers": "暴露的头部",
    "credentials": "允许携带凭证",
    "http_proxy": "HTTP 代理",
    "mcp_proxy": "MCP 代理",
    "add_router": "添加路由",
    "add_mcp_server": "添加 MCP 服务",
    "server_description": "服务器描述",
    "router_prefix": "路由前缀",
    "router_server": "路由服务器",
    "mcp_server_name": "MCP 服务名称",
    "mcp_server_type": "MCP 服务类型",
    "mcp_server_command": "MCP 服务命令",
    "mcp_server_args": "MCP 服务参数",
    "mcp_server_env": "MCP 服务环境变量",
    "mcp_server_url": "MCP 服务 URL",
    "add_env_variable": "添加环境变量",
    "env_key": "环境变量键",
    "env_value": "环境变量值",
    "add_header": "添加请求头",
    "header_key": "请求头键",
    "header_value": "请求头值",
    "tool_description": "工具描述",
    "tool_method": "工具方法",
    "tool_headers": "工具请求头",
    "tool_request_body": "工具请求体",
    "tool_response_body": "工具响应体",
    "add_tool_success": "工具添加成功",
    "add_tool_failed": "工具添加失败",
    "add_server_success": "服务器添加成功",
    "add_server_failed": "服务器添加失败",
    "add_router_success": "路由添加成功",
    "add_router_failed": "路由添加失败",
    "add_mcp_server_success": "MCP 服务添加成功",
    "add_mcp_server_failed": "MCP 服务添加失败",
    "add_env_variable_success": "环境变量添加成功",
    "add_env_variable_failed": "环境变量添加失败",
    "add_header_success": "请求头添加成功",
    "add_header_failed": "请求头添加失败",
    "remove_tool_success": "工具删除成功",
    "remove_tool_failed": "工具删除失败",
    "remove_server_success": "服务器删除成功",
    "remove_server_failed": "服务器删除失败",
    "remove_router_success": "路由删除成功",
    "remove_router_failed": "路由删除失败",
    "remove_mcp_server_success": "MCP 服务删除成功",
    "remove_mcp_server_failed": "MCP 服务删除失败",
    "remove_env_variable_success": "环境变量删除成功",
    "remove_env_variable_failed": "环境变量删除失败",
    "remove_header_success": "请求头删除成功",
    "remove_header_failed": "请求头删除失败",
    "update_tool_success": "工具更新成功",
    "update_tool_failed": "工具更新失败",
    "update_server_success": "服务器更新成功",
    "update_server_failed": "服务器更新失败",
    "update_router_success": "路由更新成功",
    "update_router_failed": "路由更新失败",
    "update_mcp_server_success": "MCP 服务更新成功",
    "update_mcp_server_failed": "MCP 服务更新失败",
    "update_env_variable_success": "环境变量更新成功",
    "update_env_variable_failed": "环境变量更新失败",
    "update_header_success": "请求头更新成功",
    "update_header_failed": "请求头更新失败",
    "http_servers": "HTTP 服务",
    "mcp_servers": "MCP 服务",
    "servers": "服务器",
    "routers": "路由",
    "tools": "工具",
    "request_body": "请求体",
    "response_body": "响应体",
    "request_body_placeholder": "例如: {\"uid\": \"{{.Args.uid}}\"}",
    "response_body_placeholder": "例如: {{.Response.Body}}",
    "origin_placeholder": "例如: https://example.com 或 *",
    "header_placeholder": "例如: Content-Type",
    "expose_header_placeholder": "例如: Content-Length",
    "sse_url": "SSE URL",
    "streamable_http_url": "Streamable HTTP URL",
    "tenant_name": "租户",
    "confirm_delete": "确定要删除网关 '{{name}}' 吗？",
    "remove_argument": "删除参数",
    "remove_tool": "删除工具",
    "tools_already_all_added": "工具已全部添加",
    "tools_none_available": "暂无可用工具",
    "remove_server": "删除服务",
    "add_origin": "添加源",
    "add_method": "添加方法",
    "add_header_custom": "添加头部",
    "add_expose_header": "添加暴露头部",
    "url_access_note": "如果使用AllInOne时，有以上两个选择，可通过Nginx访问MCP Gateway，或根据配置直接访问（若端口或路径不同，请复制后自行修改）",
    "direct_to_mcp_gateway": "直接访问MCP Gateway:",
    "server_name_limit": "{{count}}/{{max}} 字符",
    "name_length_error": "名称长度不能超过50个字符",
    "sse_prefix": "SSE 前缀",
    "sse_prefix_placeholder": "请输入 SSE 前缀",
    "prompt": "提示词",
    "prompts": "提示词",
    "prompt_name": "提示词名称",
    "arguments": "参数",
    "required": "必填",
    "remove_prompt": "删除提示词",
    "add_prompt": "添加提示词",
    "prompt_response": "提示词对话",
    "add_prompt_response": "添加对话",
    "prompt_response_role": "角色",
    "prompt_response_type": "内容类型",
    "prompt_response_text": "文本内容",
    "remove_prompt_response": "删除对话",
    "array_items_config": "数组项配置",
    "object_properties_config": "对象属性配置",
    "array_item_type": "数组项类型",
    "object_properties": "对象属性",
    "add_property": "添加属性",
    "property_name": "属性名称",
    "property_type": "属性类型",
    "property_description": "属性描述",
    "header_name_placeholder": "请输入头部名称",
    "header_value_placeholder": "请输入头部值",
    "select_file": "选择文件",
    "prefix_placeholder": "输入前缀（可选）",
    "upload_openapi_file": "上传 OpenAPI 文件",
    "drag_drop_openapi": "拖放您的 OpenAPI 规范文件",
    "or_click_to_browse": "或点击浏览文件",
    "import_openapi_description": "导入 OpenAPI 规范以创建 MCP 服务器配置"
  },
  "chat": {
    "title": "聊天",
    "send": "发送",
    "clear": "清空",
    "stop": "停止",
    "retry": "重试",
    "thinking": "思考中...",
    "generating": "正在生成...",
    "welcome_message": "你好！我是 MCP 助手，有什么我可以帮你的吗？",
    "error_message": "发生错误，请重试",
    "empty_message": "请输入消息",
    "tool_error": "加载工具失败：{{name}}",
    "tool_loading": "正在加载工具：{{name}}",
    "tool_loaded": "工具已加载：{{name}}",
    "tool_unloaded": "工具已卸载：{{name}}",
    "tool_not_found": "未找到工具：{{name}}",
    "tool_already_loaded": "工具已加载：{{name}}",
    "tool_already_unloaded": "工具已卸载：{{name}}",
    "tool_load_failed": "加载工具失败：{{name}}",
    "tool_unload_failed": "卸载工具失败：{{name}}",
    "tool_load_success": "工具加载成功：{{name}}",
    "tool_unload_success": "工具卸载成功：{{name}}",
    "tool_load_error": "加载工具出错：{{name}}",
    "tool_unload_error": "卸载工具出错：{{name}}",
    "tool_load_timeout": "加载工具超时：{{name}}",
    "tool_unload_timeout": "卸载工具超时：{{name}}",
    "tool_load_cancelled": "取消加载工具：{{name}}",
    "tool_unload_cancelled": "取消卸载工具：{{name}}",
    "tool_load_retry": "重试加载工具：{{name}}",
    "tool_unload_retry": "重试卸载工具：{{name}}",
    "tool_load_max_retries": "工具加载达到最大重试次数：{{name}}",
    "tool_unload_max_retries": "工具卸载达到最大重试次数：{{name}}",
    "tool_load_network_error": "加载工具网络错误：{{name}}",
    "tool_unload_network_error": "卸载工具网络错误：{{name}}",
    "tool_load_server_error": "加载工具服务器错误：{{name}}",
    "tool_unload_server_error": "卸载工具服务器错误：{{name}}",
    "tool_load_client_error": "加载工具客户端错误：{{name}}",
    "tool_unload_client_error": "卸载工具客户端错误：{{name}}",
    "tool_load_unknown_error": "加载工具未知错误：{{name}}",
    "tool_unload_unknown_error": "卸载工具未知错误：{{name}}",
    "message_placeholder": "输入消息...",
    "expand_history": "展开聊天历史",
    "collapse_history": "收起聊天历史",
    "expand_tools": "展开工具区域",
    "collapse_tools": "收起工具区域",
    "available_tools": "可用工具",
    "server_tools": "服务器工具",
    "you": "你",
    "arguments": "参数",
    "result": "结果",
    "mcpServers": "MCP 服务器",
    "selectMCPServers": "选择 MCP 服务器",
    "typeMessage": "输入您的消息...",
    "run_tool": "运行工具",
    "execution_completed": "执行完成",
    "tool_call_success": "工具调用成功: {{result}}",
    "reasoning_process": "推理过程",
    "tool_completed": "已完成",
    "tool_pending": "待执行",
    "notification_received": "收到来自 {{server}} 的通知: {{message}}",
    "new_chat": "新建聊天",
    "no_history": "暂无聊天记录",
    "untitled": "未命名聊天",
    "resize_history": "调整聊天历史宽度",
    "rename": "重命名",
    "experimentalWarning": {
      "title": "实验性功能",
      "description": "此 LLM 聊天功能为实验性质，可能无法完全兼容所有提供商。",
      "reportIssue": "提交问题",
      "or": "或",
      "submitPR": "提交 PR",
      "helpImprove": " 帮助我们改进兼容性。"
    },
    "delete": "删除",
    "delete_session": "删除聊天会话",
    "delete_session_confirm": "确定要删除这个聊天会话吗？此操作无法撤销。",
    "rename_title": "重命名聊天会话",
    "delete_title": "删除聊天会话",
    "delete_confirm": "确定要删除这个聊天会话吗？",
    "rename_success": "聊天会话重命名成功",
    "rename_failed": "聊天会话重命名失败",
    "delete_success": "聊天会话删除成功",
    "delete_failed": "聊天会话删除失败",
    "rename_session": "重命名聊天会话",
    "session_title_placeholder": "请输入新的会话标题",
    "systemPrompt": "系统提示词",
    "systemPromptPlaceholder": "为助手设置自定义系统提示词（可选）",
    "editSystemPrompt": "编辑系统提示词",
    "authTokenPlaceholder": "请输入认证令牌",
    "authToken": "认证令牌"
  },
  "users": {
    "title": "用户管理",
    "add": "添加用户",
    "edit": "编辑用户",
    "delete": "删除用户",
    "delete_title": "删除用户",
    "username": "用户名",
    "password": "密码",
    "role": "角色",
    "status": "状态",
    "created_at": "创建时间",
    "actions": "操作",
    "role_admin": "管理员",
    "role_normal": "普通用户",
    "status_enabled": "已启用",
    "status_disabled": "已禁用",
    "password_placeholder": "留空表示保持当前密码",
    "confirm_delete": "确定要删除这个用户吗？",
    "add_success": "用户添加成功",
    "edit_success": "用户更新成功",
    "delete_success": "用户删除成功",
    "add_failed": "添加用户失败",
    "edit_failed": "更新用户失败",
    "delete_failed": "删除用户失败",
    "enable_success": "用户启用成功",
    "disable_success": "用户禁用成功",
    "enable_failed": "启用用户失败",
    "disable_failed": "禁用用户失败",
    "select_tenants": "选择租户",
    "select_tenant": "选择租户",
    "search_tenants": "搜索租户...",
    "update_tenants_success": "更新用户租户关联成功",
    "update_tenants_failed": "更新用户租户关联失败",
    "no_tenants": "未关联任何租户",
    "manage_tenants": "管理租户",
    "tenants": "关联租户"
  },
  "tenants": {
    "title": "租户管理",
    "add": "添加租户",
    "edit": "编辑租户",
    "delete": "删除租户",
    "delete_title": "删除租户",
    "name": "名称",
    "name_placeholder": "仅支持英文和数字",
    "prefix": "前缀",
    "prefix_placeholder": "例如 tenant1 或 /tenant2/abc(根/不可用)",
    "description": "描述",
    "status": "状态",
    "created_at": "创建时间",
    "actions": "操作",
    "status_enabled": "已启用",
    "status_disabled": "已禁用",
    "confirm_delete": "确定要删除这个租户吗？",
    "add_success": "租户添加成功",
    "edit_success": "租户更新成功",
    "delete_success": "租户删除成功",
    "add_failed": "添加租户失败",
    "edit_failed": "更新租户失败",
    "delete_failed": "删除租户失败",
    "enable_success": "租户启用成功",
    "disable_success": "租户禁用成功",
    "enable_failed": "启用租户失败",
    "disable_failed": "禁用租户失败",
    "no_description": "暂无描述",
    "save": "保存",
    "prefix_conflict": "前缀已存在，请使用其他前缀",
    "name_conflict": "租户名称已存在，请使用其他名称",
    "prefix_path_conflict": "前缀路径冲突，不能添加已存在前缀的子路径或父路径",
    "root_prefix_not_allowed": "不允许使用根级别目录 '/' 作为前缀"
  },
  "errors": {
    "required": "此字段为必填项",
    "invalid_email": "无效的邮箱地址",
    "invalid_password": "无效的密码",
    "invalid_username": "无效的用户名",
    "invalid_url": "无效的URL",
    "network_error": "网络错误，请检查网络连接",
    "server_error": "服务器错误，请稍后重试",
    "timeout": "请求超时",
    "unknown": "未知错误",
    "check_system_status": "检查系统状态失败",
    "fetch_mcp_servers": "获取 MCP 服务列表失败",
    "fetch_tools": "获取工具失败：{{error}}",
    "invalid_yaml": "无效的 YAML 格式",
    "fetch_users": "获取用户列表失败",
    "fetch_user": "获取用户信息失败",
    "invalid_tool_name": "工具名称格式错误",
    "invalid_tool_arguments": "工具参数格式错误",
    "server_not_connected": "服务器 {{server}} 未连接",
    "tool_call_failed": "工具调用失败: {{error}}",
    "fetch_chat_history": "获取聊天历史失败: {{error}}",
    "load_messages": "加载消息失败: {{error}}",
    "mcp_server_error": "MCP 服务 {{server}} 发生错误: {{error}}",
    "connect_mcp_server": "连接 MCP 服务 {{server}} 失败",
    "no_server_config": "未找到服务器 {{server}} 的配置",
    "terminate_session": "终止会话失败: {{error}}",
    "disconnect_failed": "断开连接失败: {{error}}",
    "websocket_disconnected": "WebSocket 连接已断开",
    "websocket_error": "WebSocket 发生错误: {{error}}",
    "invalid_openapi_file": "请选择有效的 OpenAPI 规范文件",
    "import_openapi_success": "OpenAPI 规范导入成功",
    "import_openapi_failed": "OpenAPI 规范导入失败",
    "get_tools_failed": "获取工具列表失败: {{error}}",
    "call_tool_failed": "调用工具 {{toolName}} 失败: {{error}}",
    "fetch_mcp_server": "获取 MCP 服务失败",
    "create_mcp_server": "创建 MCP 服务失败",
    "update_mcp_server": "更新 MCP 服务配置失败",
    "delete_mcp_server": "删除 MCP 服务失败",
    "sync_mcp_server": "同步 MCP 服务失败",
    "fetch_chat_messages": "获取聊天消息失败",
    "fetch_chat_sessions": "获取聊天会话列表失败",
    "fetch_tenants": "获取租户列表失败",
    "fetch_tenant": "获取租户详情失败",
    "create_tenant": "创建租户失败",
    "update_tenant": "更新租户失败",
    "delete_tenant": "删除租户失败",
    "fetch_authorized_tenants": "获取有权限的租户失败",
    "generic": "发生错误，请重试。",
    "not_found": "未找到请求的资源。",
    "unauthorized": "您无权执行此操作。",
    "forbidden": "您没有权限访问此资源。",
    "internal_server": "服务器内部错误，请稍后重试。",
    "bad_request": "请求错误，请检查您的输入。",
    "conflict": "与现有资源冲突。",
    "validation": "验证错误，请检查您的输入。",
    "parse_config": "解析 {{name}} 的配置失败。",
    "namespace_permission_error": "用户没有权限配置此命名空间",
    "tenant_permission_error": "用户没有权限配置此租户",
    "router_prefix_error": "路由前缀必须以租户前缀开头, 且不能为空",
    "tenant_required": "租户字段不能为空",
    "tenant_not_found": "指定前缀的租户不存在",
    "validate_router_prefix_failed": "验证路由前缀失败",
    "export_mcp_server": "导出 MCP 服务失败",
    "set_active_version": "设置版本为激活状态失败",
    "llm_request_failed": "LLM 请求失败：{{error}}",
    "save_chat_message": "保存聊天消息失败"
  },
  "mcp": {
    "configVersions": {
      "title": "配置版本",
      "name": "名称",
      "tenant": "租户",
      "version": "版本",
      "created_by": "创建者",
      "created_at": "创建时间",
      "action_type": "操作类型",
      "action_types": {
        "create": "创建",
        "update": "更新",
        "delete": "删除",
        "revert": "回滚"
      },
      "active": "状态",
      "inactive": "未激活",
      "actions": "操作",
      "compare": "比较",
      "compare_versions": "版本比较",
      "compare_with_previous": "与上一版本比较",
      "compare_with_latest": "与最新版本比较",
      "rollback": "回滚到这个版本",
      "no_previous_version": "没有可用的上一版本",
      "no_latest_version": "没有可用的最新版本",
      "show_all": "显示全部",
      "show_diff_only": "仅显示差异",
      "select_config": "选择配置",
      "select_tenant": "选择租户",
      "fetch_names_error": "获取名称失败",
      "fetch_error": "获取失败",
      "set_active_success": "设置为活动版本成功",
      "set_active_error": "设置为活动版本失败"
    }
  },
  "llm": {
    "title": "LLM 提供商",
    "description": "配置语言模型提供商",
    "management": "提供商管理",
    "providers": "语言模型提供商",
    "searchProviders": "搜索提供商...",
    "searchProvidersPlaceholder": "搜索提供商",
    "searchModels": "搜索模型...",
    "addProvider": "添加提供商",
    "addFirstProvider": "添加您的第一个提供商",
    "noProviders": "尚未配置任何提供商",
    "enabledCount": "已启用 {{count}} 个",
    "enabled": "已启用",
    "disabled": "已禁用",
    "custom": "自定义",
    "configuration": "配置",
    "models": "模型",
    "configure": "配置",
    "test": "测试连接",
    "testing": "测试中...",
    "testSuccess": "连接成功",
    "testFailed": "连接失败：{{error}}",
    "testError": "测试错误：{{error}}",
    "connected": "已连接",
    "export": "导出配置",
    "import": "导入配置",
    "reset": "重置为默认",
    "resetTooltip": "将所有提供商重置为默认配置",
    "resetConfirm": "确定要将所有提供商重置为默认配置吗？这将移除所有自定义设置。",
    "resetSuccess": "成功重置为默认配置",
    "importSuccess": "配置导入成功",
    "importError": "导入失败：{{error}}",
    "addSuccess": "提供商 '{{name}}' 添加成功",
    "updateSuccess": "提供商配置更新成功",
    "deleteSuccess": "提供商 '{{name}}' 删除成功",
    "deleteConfirm": "确定要删除提供商 '{{name}}' 吗？此操作无法撤销。",
    "selectProvider": "选择提供商",
    "customProvider": "自定义提供商",
    "addCustomProvider": "添加自定义提供商",
    "customProviderDesc": "配置自定义的 OpenAI 兼容 API 提供商",
    "providerName": "提供商名称",
    "providerNamePlaceholder": "输入提供商名称",
    "nameRequired": "提供商名称为必填项",
    "descriptionPlaceholder": "输入提供商描述（可选）",
    "providerConfigNote": "添加提供商后，您可以配置 API 密钥和其他设置。",
    "configureProvider": "配置 {{name}}",
    "apiKey": "API 密钥",
    "apiKeyPlaceholder": "输入您的 API 密钥",
    "baseURL": "基础 URL",
    "baseURLPlaceholder": "https://api.openai.com/v1",
    "organization": "组织",
    "organizationPlaceholder": "输入组织 ID（可选）",
    "fetchOnClient": "客户端请求",
    "fetchOnClientDesc": "直接从浏览器发起 API 调用，而不是通过服务器",
    "clientMode": "客户端模式",
    "customEndpoint": "自定义端点",
    "modelParameters": "模型参数",
    "temperature": "温度",
    "topP": "Top-p",
    "maxTokens": "最大 Token 数",
    "maxOutput": "最大输出",
    "timeout": "超时",
    "contextWindow": "上下文窗口",
    "website": "官方网站",
    "documentation": "文档",
    "availableModels": "可用模型",
    "enabledModels": "已启用模型",
    "noModels": "没有可用模型",
    "modelsCount": "{{count}} 个模型",
    "add": "添加",
    "noProviderSelected": "未选择提供商",
    "selectProviderFirst": "请先选择一个 LLM 提供商",
    "openSettings": "打开设置",
    "chatSettings": "聊天设置",
    "manageLLMProviders": "管理 LLM 提供商",
    "generating": "正在生成回复...",
    "selectProviderToConfig": "选择一个提供商进行配置",
    "selectProviderToStart": "从左侧选择一个提供商开始配置",
    "modelsEnabled": "个模型已启用",
    "fetchModels": "获取模型",
    "fetching": "获取中...",
    "addCustomModel": "添加自定义模型",
    "modelId": "模型 ID",
    "modelName": "模型名称",
    "modelNameRequired": "模型名称为必填项",
    "addModelSuccess": "模型添加成功",
    "deleteModelSuccess": "模型删除成功",
    "fetchModelsSuccess": "成功获取 {{count}} 个新模型",
    "fetchModelsFailed": "获取模型失败：{{error}}",
    "apiKeyRequired": "获取模型需要 API 密钥",
    "updateFailed": "更新配置失败",
    "provider": "提供商",
    "model": "模型",
    "selectModel": "选择模型",
    "selectProviderAndModel": "请先选择提供商和模型",
    "noModelsAvailable": "没有可用的模型",
    "useClientFetchToLoadModels": "使用'获取模型'来加载可用模型",
    "tryOtherSearchTerms": "尝试其他搜索词",
    "providerDescriptions": {
      "ai21": "AI21 Labs 为企业构建基础模型和人工智能系统，加速生成性人工智能在生产中的应用。",
      "ai360": "360 AI 是 360 公司推出的 AI 模型和服务平台，提供多种先进的自然语言处理模型，包括 360GPT2 Pro、360GPT Pro、360GPT Turbo 和 360GPT Turbo Responsibility 8K。这些模型结合了大规模参数和多模态能力，广泛应用于文本生成、语义理解、对话系统与代码生成等领域。通过灵活的定价策略，360 AI 满足多样化用户需求，支持开发者集成，推动智能化应用的革新和发展。",
      "anthropic": "Anthropic 是一家专注于人工智能研究和开发的公司，提供了一系列先进的语言模型，如 Claude 3.5 Sonnet、Claude 3 Sonnet、Claude 3 Opus 和 Claude 3 Haiku。这些模型在智能、速度和成本之间取得了理想的平衡，适用于从企业级工作负载到快速响应的各种应用场景。Claude 3.5 Sonnet 作为其最新模型，在多项评估中表现优异，同时保持了较高的性价比。",
      "azure": "Azure 提供多种先进的AI模型，包括GPT-3.5和最新的GPT-4系列，支持多种数据类型和复杂任务，致力于安全、可靠和可持续的AI解决方案。",
      "azureai": "Azure 提供多种先进的AI模型，包括GPT-3.5和最新的GPT-4系列，支持多种数据类型和复杂任务，致力于安全、可靠和可持续的AI解决方案。",
      "baichuan": "百川智能是一家专注于人工智能大模型研发的公司，其模型在国内知识百科、长文本处理和生成创作等中文任务上表现卓越，超越了国外主流模型。百川智能还具备行业领先的多模态能力，在多项权威评测中表现优异。其模型包括 Baichuan 4、Baichuan 3 Turbo 和 Baichuan 3 Turbo 128k 等，分别针对不同应用场景进行优化，提供高性价比的解决方案。",
      "bedrock": "Bedrock 是亚马逊 AWS 提供的一项服务，专注于为企业提供先进的 AI 语言模型和视觉模型。其模型家族包括 Anthropic 的 Claude 系列、Meta 的 Llama 3.1 系列等，涵盖从轻量级到高性能的多种选择，支持文本生成、对话、图像处理等多种任务，适用于不同规模和需求的企业应用。",
      "cloudflare": "在 Cloudflare 的全球网络上运行由无服务器 GPU 驱动的机器学习模型。",
      "cohere": "Cohere 为您带来最前沿的多语言模型、先进的检索功能以及为现代企业量身定制的 AI 工作空间 — 一切都集成在一个安全的平台中。",
      "deepseek": "DeepSeek 是一家专注于人工智能技术研究和应用的公司，其最新模型 DeepSeek-V3 多项评测成绩超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，性能对齐领军闭源模型 GPT-4o 与 Claude-3.5-Sonnet。",
      "fireworksai": "Fireworks AI 是一家领先的高级语言模型服务商，专注于功能调用和多模态处理。其最新模型 Firefunction V2 基于 Llama-3，优化用于函数调用、对话及指令跟随。视觉语言模型 FireLLaVA-13B 支持图像和文本混合输入。其他 notable 模型包括 Llama 系列和 Mixtral 系列，提供高效的多语言指令跟随与生成支持。",
      "giteeai": "Gitee AI 的 Serverless API 为 AI 开发者提供开箱即用的大模型推理 API 服务。",
      "github": "通过GitHub模型，开发人员可以成为AI工程师，并使用行业领先的AI模型进行构建。",
      "google": "Google 的 Gemini 系列是其最先进、通用的 AI模型，由 Google DeepMind 打造，专为多模态设计，支持文本、代码、图像、音频和视频的无缝理解与处理。适用于从数据中心到移动设备的多种环境，极大提升了AI模型的效率与应用广泛性。",
      "groq": "Groq 的 LPU 推理引擎在最新的独立大语言模型（LLM）基准测试中表现卓越，以其惊人的速度和效率重新定义了 AI 解决方案的标准。Groq 是一种即时推理速度的代表，在基于云的部署中展现了良好的性能。",
      "higress": "Higress 是一款云原生 API 网关，在阿里内部为解决 Tengine reload 对长连接业务有损，以及 gRPC/Dubbo 负载均衡能力不足而诞生。",
      "huggingface": "HuggingFace Inference API 提供了一种快速且免费的方式，让您可以探索成千上万种模型，适用于各种任务。无论您是在为新应用程序进行原型设计，还是在尝试机器学习的功能，这个 API 都能让您即时访问多个领域的高性能模型。",
      "hunyuan": "由腾讯研发的大语言模型，具备强大的中文创作能力，复杂语境下的逻辑推理能力，以及可靠的任务执行能力",
      "infiniai": "为应用开发者提供高性能、易上手、安全可靠的大模型服务，覆盖从大模型开发到大模型服务化部署的全流程。",
      "internlm": "致力于大模型研究与开发工具链的开源组织。为所有 AI 开发者提供高效、易用的开源平台，让最前沿的大模型与算法技术触手可及",
      "jina": "Jina AI 成立于 2020 年，是一家领先的搜索 AI 公司。我们的搜索底座平台包含了向量模型、重排器和小语言模型，可帮助企业构建可靠且高质量的生成式AI和多模态的搜索应用。",
      "lmstudio": "LM Studio 是一个用于在您的计算机上开发和实验 LLMs 的桌面应用程序。",
      "minimax": "MiniMax 是 2021 年成立的通用人工智能科技公司，致力于与用户共创智能。MiniMax 自主研发了不同模态的通用大模型，其中包括万亿参数的 MoE 文本大模型、语音大模型以及图像大模型。并推出了海螺 AI 等应用。",
      "mistral": "Mistral 提供先进的通用、专业和研究型模型，广泛应用于复杂推理、多语言任务、代码生成等领域，通过功能调用接口，用户可以集成自定义功能，实现特定应用。",
      "moonshot": "Moonshot 是由北京月之暗面科技有限公司推出的开源平台，提供多种自然语言处理模型，应用领域广泛，包括但不限于内容创作、学术研究、智能推荐、医疗诊断等，支持长文本处理和复杂生成任务。",
      "novita": "Novita AI 是一个提供多种大语言模型与 AI 图像生成的 API 服务的平台，灵活、可靠且具有成本效益。它支持 Llama3、Mistral 等最新的开源模型，并为生成式 AI 应用开发提供了全面、用户友好且自动扩展的 API 解决方案，适合 AI 初创公司的快速发展。",
      "nvidia": "NVIDIA NIM™ 提供容器，可用于自托管 GPU 加速推理微服务，支持在云端、数据中心、RTX™ AI 个人电脑和工作站上部署预训练和自定义 AI 模型。",
      "ollama": "Ollama 提供的模型广泛涵盖代码生成、数学运算、多语种处理和对话互动等领域，支持企业级和本地化部署的多样化需求。",
      "openai": "OpenAI 是全球领先的人工智能研究机构，其开发的模型如GPT系列推动了自然语言处理的前沿。OpenAI 致力于通过创新和高效的AI解决方案改变多个行业。他们的产品具有显著的性能和经济性，广泛用于研究、商业和创新应用。",
      "openrouter": "OpenRouter 是一个提供多种前沿大模型接口的服务平台，支持 OpenAI、Anthropic、LLaMA 及更多，适合多样化的开发和应用需求。用户可根据自身需求灵活选择最优的模型和价格，助力AI体验的提升。",
      "perplexity": "Perplexity 是一家领先的对话生成模型提供商，提供多种先进的Llama 3.1模型，支持在线和离线应用，特别适用于复杂的自然语言处理任务。",
      "ppio": "PPIO 派欧云提供稳定、高性价比的开源模型 API 服务，支持 DeepSeek 全系列、Llama、Qwen 等行业领先大模型。",
      "qiniu": "七牛作为老牌云服务厂商，提供高性价比稳定的实时、批量 AI 推理服务，简单易用。",
      "qwen": "通义千问是阿里云自主研发的超大规模语言模型，具有强大的自然语言理解和生成能力。它可以回答各种问题、创作文字内容、表达观点看法、撰写代码等，在多个领域发挥作用。",
      "sambanova": "SambaNova Cloud 可让开发者轻松使用最佳的开源模型，并享受最快的推理速度。",
      "search1api": "Search1API 提供可根据需要自行联网的 DeepSeek 系列模型的访问，包括标准版和快速版本，支持多种参数规模的模型选择。",
      "sensenova": "商汤日日新，依托商汤大装置的强大的基础支撑，提供高效易用的全栈大模型服务。",
      "siliconcloud": "SiliconCloud，基于优秀开源基础模型的高性价比 GenAI 云服务",
      "spark": "科大讯飞星火大模型提供多领域、多语言的强大 AI 能力，利用先进的自然语言处理技术，构建适用于智能硬件、智慧医疗、智慧金融等多种垂直场景的创新应用。",
      "stepfun": "阶级星辰大模型具备行业领先的多模态及复杂推理能力，支持超长文本理解和强大的自主调度搜索引擎功能。",
      "taichu": "中科院自动化研究所和武汉人工智能研究院推出新一代多模态大模型，支持多轮问答、文本创作、图像生成、3D理解、信号分析等全面问答任务，拥有更强的认知、理解、创作能力，带来全新互动体验。",
      "tencentcloud": "知识引擎原子能力（LLM Knowledge Engine Atomic Power）基于知识引擎研发的知识问答全链路能力，面向企业及开发者，提供灵活组建及开发模型应用的能力。您可通过多款原子能力组建您专属的模型服务，调用文档解析、拆分、embedding、多轮改写等服务进行组装，定制企业专属 AI 业务。",
      "togetherai": "Together AI 致力于通过创新的 AI 模型实现领先的性能，提供广泛的自定义能力，包括快速扩展支持和直观的部署流程，满足企业的各种需求。",
      "upstage": "Upstage 专注于为各种商业需求开发AI模型，包括 Solar LLM 和文档 AI，旨在实现工作的人造通用智能（AGI）。通过 Chat API 创建简单的对话代理，并支持功能调用、翻译、嵌入以及特定领域应用。",
      "vertexai": "Google 的 Gemini 系列是其最先进、通用的 AI模型，由 Google DeepMind 打造，专为多模态设计，支持文本、代码、图像、音频和视频的无缝理解与处理。适用于从数据中心到移动设备的多种环境，极大提升了AI模型的效率与应用广泛性。",
      "vllm": "vLLM 是一个快速且易于使用的库，用于 LLM 推理和服务。",
      "volcengine": "字节跳动推出的大模型服务的开发平台，提供功能丰富、安全以及具备价格竞争力的模型调用服务，同时提供模型数据、精调、推理、评测等端到端功能，全方位保障您的 AI 应用开发落地。",
      "wenxin": "企业级一站式大模型与AI原生应用开发及服务平台，提供最全面易用的生成式人工智能模型开发、应用开发全流程工具链",
      "xai": "xAI 是一家致力于构建人工智能以加速人类科学发现的公司。我们的使命是推动我们对宇宙的共同理解。",
      "xinference": "Xorbits Inference (Xinference) 是一个开源平台，用于简化各种 AI 模型的运行和集成。借助 Xinference，您可以使用任何开源 LLM、嵌入模型和多模态模型在云端或本地环境中运行推理，并创建强大的 AI 应用。",
      "zeroone": "零一万物致力于推动以人为本的AI 2.0技术革命，旨在通过大语言模型创造巨大的经济和社会价值，并开创新的AI生态与商业模式。",
      "zhipu": "智谱 AI 提供多模态与语言模型的开放平台，支持广泛的AI应用场景，包括文本处理、图像理解与编程辅助等。"
      },
    "modelDescriptions": {
      "openai": {
        "gpt-4.1": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。",
        "gpt-4.1-mini": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。",
        "gpt-4.1-nano": "GPT-4.1 nano 是速度最快、最具成本效益的 GPT-4.1 模型。",
        "chatgpt-4o-latest": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "o3-mini": "o3-mini 在与 o1-mini 相同的成本和延迟目标下提供高智能。",
        "o3": "o3 是 OpenAI 最新的推理模型，具有增强的逻辑思考能力，特别擅长数学、科学和编程等复杂问题求解。",
        "o4-mini": "o4-mini 是 GPT-4 系列中最新的紧凑型模型，以更低的成本为广泛的任务提供改进的效率和性能。",
        "o1-mini": "o1-mini 是一个快速、经济高效的推理模型，专为编程、数学和科学应用场景而设计。该模型具有 128K 上下文和 2023 年 10 月的知识截止日期。",
        "o1": "o1 是 OpenAI 的新推理模型，支持图像和文本输入以及文本输出，适用于需要广泛通用知识的复杂任务。该模型具有 200K 上下文和 2023 年 10 月的知识截止日期。",
        "o1-preview": "o1 是 OpenAI 新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有 128K 上下文和 2023 年 10 月的知识截止日期。",
        "gpt-4.5-preview": "GPT-4.5 的研究预览版，它是我们迄今为止最大、最强大的 GPT 模型。它拥有广泛的世界知识，并能更好地理解用户意图，使其在创造性任务和自主规划方面表现出色。GPT-4.5 可接受文本和图像输入，并生成文本输出（包括结构化输出）。支持关键的开发者功能，如函数调用、批量 API 和流式输出。在需要创造性、开放式思考和对话的任务（如写作、学习或探索新想法）中，GPT-4.5 表现尤为出色。知识截止日期为 2023 年 10 月。",
        "gpt-4o-mini": "GPT-4o mini 是 OpenAI 在 GPT-4 Omni 之后发布的最新模型，支持图像文本输入并输出文本。作为他们最先进的小型模型，它比其他最近的前沿模型便宜得多，比 GPT-3.5 Turbo 便宜 60% 以上。它在聊天、文本和视觉方面保持强劲性能，并在 API 中支持文本和视觉。",
        "gpt-4o-2024-11-20": "ChatGPT-4o 是一款动态模型，实时更新以保持最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "gpt-4o": "ChatGPT-4o 是一款动态模型，实时更新以保持最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "gpt-4o-2024-05-13": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "gpt-4o-audio-preview": "GPT-4o 实时版本，支持音频和文本实时输入输出",
        "gpt-4-turbo": "GPT-4 Turbo 具有改进的指令遵循、JSON 模式、可重现输出、并行函数调用等功能。最多返回 4,096 个输出令牌。",
        "gpt-4-turbo-2024-04-09": "GPT-4 Turbo with Vision。具有视觉能力的最新 GPT-4 Turbo 模型。视觉请求现在可以使用 JSON 模式和函数调用。",
        "gpt-4-turbo-preview": "GPT-4 Turbo 预览模型，旨在减少模型不完成任务的「懒惰」情况。",
        "gpt-4-0125-preview": "GPT-4 Turbo 预览模型。旨在减少模型不完成任务的「懒惰」情况的最新 GPT-4 模型。",
        "gpt-4-1106-preview": "GPT-4 Turbo 预览模型。旨在减少模型不完成任务的「懒惰」情况的最新 GPT-4 模型。",
        "gpt-4": "比任何 GPT-3.5 模型更强大，能够执行更复杂的任务，并针对聊天进行了优化。",
        "gpt-4-0613": "2023 年 6 月 13 日的 gpt-4 快照，改进了函数调用支持。",
        "gpt-4-32k": "与标准 gpt-4 模式相同的功能，但上下文长度是其 4 倍。",
        "gpt-3.5-turbo": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，目前指向 gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-0125": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，目前指向 gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-1106": "GPT-3.5 Turbo 模型，具有改进的指令遵循、JSON 模式、可重现输出、并行函数调用等功能。",
        "gpt-3.5-turbo-instruct": "类似于 text-davinci-003 的功能，但与传统的 Completions 端点兼容，而不是 Chat Completions。"
      },
    "Skylark2-pro-4k": "云雀（Skylark）第二代模型，Skylark2-pro模型有较高的模型精度，适用于较为复杂的文本生成场景，如专业领域文案生成、小说创作、高质量翻译等，上下文窗口长度为4k。",
    "Qwen/QVQ-72B-Preview": "QVQ-72B-Preview 是由 Qwen 团队开发的专注于视觉推理能力的研究型模型，其在复杂场景理解和解决视觉相关的数学问题方面具有独特优势。",
    "llama3.1:70b": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。",
    "openai/gpt-4o": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "gemini-1.5-flash-exp-0827": "Gemini 1.5 Flash 0827 提供了优化后的多模态处理能力，适用多种复杂任务场景。",
    "gemini-1.5-flash-002": "Gemini 1.5 Flash 002 是一款高效的多模态模型，支持广泛应用的扩展。",
    "gpt-3.5-turbo-0125": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
    "thudm/glm-4-32b:free": "GLM-4-32B-0414 是一个 32B 双语（中英）开放权重语言模型，针对代码生成、函数调用和代理式任务进行了优化。它在 15T 高质量和重推理数据上进行了预训练，并使用人类偏好对齐、拒绝采样和强化学习进一步完善。该模型在复杂推理、工件生成和结构化输出任务方面表现出色，在多个基准测试中达到了与 GPT-4o 和 DeepSeek-V3-0324 相当的性能。",
    "ministral-3b-latest": "Ministral 3B 是Mistral的世界顶级边缘模型。",
    "compound-beta-mini": "Compound-beta-mini 是一个复合 AI 系统，由 GroqCloud 中已经支持的公开可用模型提供支持，可以智能地、有选择地使用工具来回答用户查询。",
    "SenseChat-Turbo": "适用于快速问答、模型微调场景",
    "glm-4v-plus": "GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。",
    "step-1o-vision-32k": "该模型拥有强大的图像理解能力。相比于 step-1v 系列模型，拥有更强的视觉性能。",
    "gpt-4-vision-preview": "GPT-4 视觉预览版，专为图像分析和处理任务设计。",
    "mistral-large-instruct": "Mistral-Large-Instruct-2407 是一款先进的稠密大型语言模型（LLM），拥有 1230 亿参数，具备最先进的推理、知识和编码能力。",
    "gemini-1.5-flash-8b": "Gemini 1.5 Flash 8B 是一款高效的多模态模型，支持广泛应用的扩展。",
    "google/gemini-2.0-flash-001": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。",
    "gemma2": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。",
    "x1": "Spark X1 模型将进一步升级，在原来数学任务国内领先基础上，推理、文本生成、语言理解等通用任务实现效果对标 OpenAI o1 和 DeepSeek R1。",
    "ERNIE-Speed-128K": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。",
    "qwen2.5:0.5b": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "Yi-34B-Chat": "Yi-1.5-34B 在保持原系列模型优秀的通用语言能力的前提下，通过增量训练 5 千亿高质量 token，大幅提高了数学逻辑、代码能力。",
    "SenseCat-5-1202": "是基于V5.5的最新版本，较上版本在中英文基础能力，聊天，理科知识， 文科知识，写作，数理逻辑，字数控制 等几个维度的表现有显著提升。",
    "hunyuan-lite-vision": "混元最新7B多模态模型，上下文窗口32K，支持中英文场景的多模态对话、图像物体识别、文档表格理解、多模态数学等，在多个维度上评测指标优于7B竞品模型。",
    "chatglm3-6b-base": "ChatGLM3-6b-base 是由智谱开发的 ChatGLM 系列最新一代的 60 亿参数规模的开源的基础模型。",
    "ernie-4.5-turbo-32k": "文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。文本创作、知识问答等能力提升显著。输出长度及整句时延相较ERNIE 4.5有所增加。",
    "pixtral-large-latest": "Pixtral Large 是一款拥有 1240 亿参数的开源多模态模型，基于 Mistral Large 2 构建。这是我们多模态家族中的第二款模型，展现了前沿水平的图像理解能力。",
    "Qwen2.5-Coder-14B-Instruct": "Qwen2.5-Coder-14B-Instruct 是一款基于大规模预训练的编程指令模型，具备强大的代码理解和生成能力，能够高效地处理各种编程任务，特别适合智能代码编写、自动化脚本生成和编程问题解答。",
    "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "gemini-2.0-flash-001": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。",
    "01-ai/yi-1.5-9b-chat": "零一万物，最新开源微调模型，90亿参数，微调支持多种对话场景，高质量训练数据，对齐人类偏好。",
    "meta-llama/Meta-Llama-3.1-405B-Instruct": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。",
    "google/gemini-2.5-pro-preview-03-25": "Gemini 2.5 Pro 是 Google 最先进的 AI 模型，专为高级推理、编码、数学和科学任务而设计。它采用“思考”能力，使其能够以更高的准确性和细致的上下文处理来推理响应。Gemini 2.5 Pro 在多个基准测试中取得了顶级性能，包括在 LMArena 排行榜上排名第一，反映了卓越的人类偏好对齐和复杂问题解决能力。",
    "step-1-flash": "高速模型，适合实时对话。",
    "360gpt-turbo-responsibility-8k": "360GPT Turbo Responsibility 8K 强调语义安全和责任导向，专为对内容安全有高度要求的应用场景设计，确保用户体验的准确性与稳健性。",
    "claude-3-sonnet-20240229": "Claude 3 Sonnet 在智能和速度方面为企业工作负载提供了理想的平衡。它以更低的价格提供最大效用，可靠且适合大规模部署。",
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": "Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。",
    "cohere-command-r-plus": "Command R+是一个最先进的RAG优化模型，旨在应对企业级工作负载。",
    "SenseNova-V6-Turbo": "实现图片、文本、视频能力的原生统一，突破传统多模态分立局限，在多模基础能力、语言基础能力等核心维度全面领先，文理兼修，在多项测评中多次位列国内外第一梯队水平。",
    "glm-4-9b-chat": "GLM-4-9B-Chat 是智谱 AI 推出的最新一代预训练模型 GLM-4-9B 的人类偏好对齐版本。",
    "InternVL2.5-26B": "InternVL2.5-26B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
    "qwen/qwen3-235b-a22b:free": "Qwen3-235B-A22B 是由 Qwen 开发的 235B 参数专家混合 (MoE) 模型，每次前向传递激活 22B 参数。它支持在用于复杂推理、数学和代码任务的“思考”模式与用于一般对话效率的“非思考”模式之间无缝切换。该模型展示了强大的推理能力、多语言支持（100 多种语言和方言）、高级指令遵循和代理工具调用能力。它原生处理 32K 令牌上下文窗口，并使用基于 YaRN 的扩展扩展到 131K 令牌。",
    "qwen2.5-coder-instruct": "Qwen2.5-Coder 是 Qwen 系列中最新的代码专用大型语言模型（前身为 CodeQwen）。",
    "gemini-1.5-pro-002": "Gemini 1.5 Pro 002 是最新的生产就绪模型，提供更高质量的输出，特别在数学、长上下文和视觉任务方面有显著提升。",
    "qwen/qwen3-32b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "deepseek-r1-distill-llama-70b": "DeepSeek-R1-Distill-Llama-70B是DeepSeek-R1基于Llama3.3-70B-Instruct的蒸馏模型。",
    "openai/o1-preview": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。",
    "Qwen/Qwen2.5-72B-Instruct": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。",
    "SenseNova-V6-Reasoner": "兼顾视觉、语言深度推理，实现慢思考和深度推理，呈现完整的思维链过程。",
    "deepseek-r1-online": "DeepSeek R1 满血版，拥有 671B 参数，支持实时联网搜索，具有更强大的理解和生成能力。",
    "meta.llama3-70b-instruct-v1:0": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放大型语言模型 (LLM)，旨在帮助他们构建、实验并负责任地扩展他们的生成 AI 想法。作为全球社区创新的基础系统的一部分，它非常适合内容创建、对话 AI、语言理解、研发和企业应用。",
    "command-light-nightly": "为了缩短主要版本发布之间的时间间隔，我们推出了 Command 模型的每夜版本。对于 command-light 系列，这一版本称为 command-light-nightly。请注意，command-light-nightly 是最新、最具实验性且（可能）不稳定的版本。每夜版本会定期更新，且不会提前通知，因此不建议在生产环境中使用。",
    "llama-3.1-8b-instant": "Llama 3.1 8B 是一款高效能模型，提供了快速的文本生成能力，非常适合需要大规模效率和成本效益的应用场景。",
    "360zhinao2-o1": "360zhinao2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。",
    "Pro/Qwen/Qwen2-7B-Instruct": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
    "qwen-coder-turbo-latest": "通义千问代码模型。",
    "llama-3.2-90b-vision-instruct": "适用于视觉理解代理应用的高级图像推理能力。",
    "codeqwen": "CodeQwen1.5 是基于大量代码数据训练的大型语言模型，专为解决复杂编程任务。",
    "qwen/qwen3-235b-a22b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "internlm/internlm2_5-7b-chat": "InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域",
    "togethercomputer/StripedHyena-Nous-7B": "StripedHyena Nous (7B) 通过高效的策略和模型架构，提供增强的计算能力。",
    "llama3.1": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。",
    "command-r-03-2024": "Command R 是一个遵循指令的对话模型，在语言任务方面表现出更高的质量、更可靠，并且相比以往模型具有更长的上下文长度。它可用于复杂的工作流程，如代码生成、检索增强生成（RAG）、工具使用和代理。",
    "ERNIE-4.0-Turbo-8K-Latest": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀",
    "yi-lightning-lite": "轻量化版本，推荐使用 yi-lightning。",
    "qwen/qwen2.5-32b-instruct": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "thudm/glm-4-9b:free": "GLM-4-9B-0414 是 THUDM 开发的 GLM-4 系列中的 90 亿参数语言模型。GLM-4-9B-0414 使用与其较大的 32B 对应模型相同的强化学习和对齐策略进行训练，相对于其规模实现了高性能，使其适用于仍需要强大语言理解和生成能力的资源受限部署。",
    "qwen-turbo": "通义千问超大规模语言模型，支持中文、英文等不同语言输入。",
    "qwen2.5-instruct": "Qwen2.5 是 Qwen 大型语言模型的最新系列。对于 Qwen2.5，我们发布了多个基础语言模型和指令微调语言模型，参数范围从 5 亿到 72 亿不等。",
    "gpt-4o-realtime-preview": "GPT-4o 实时版本，支持音频和文本实时输入输出",
    "open-mistral-7b": "Mistral 7B是一款紧凑但高性能的模型，擅长批量处理和简单任务，如分类和文本生成，具有良好的推理能力。",
    "gemini-1.5-flash-001": "Gemini 1.5 Flash 001 是一款高效的多模态模型，支持广泛应用的扩展。",
    "moonshot-v1-auto": "Moonshot V1 Auto 可以根据当前上下文占用的 Tokens 数量来选择合适的模型",
    "thudm/glm-4-32b": "GLM-4-32B-0414 是一个 32B 双语（中英）开放权重语言模型，针对代码生成、函数调用和代理式任务进行了优化。它在 15T 高质量和重推理数据上进行了预训练，并使用人类偏好对齐、拒绝采样和强化学习进一步完善。该模型在复杂推理、工件生成和结构化输出任务方面表现出色，在多个基准测试中达到了与 GPT-4o 和 DeepSeek-V3-0324 相当的性能。",
    "ernie-4.5-turbo-vl-32k": "文心一言大模型全新版本，图片理解、创作、翻译、代码等能力显著提升，首次支持32K上下文长度，首Token时延显著降低。",
    "thudm/glm-z1-rumination-32b": "GLM Z1 Rumination 32B 是 GLM-4-Z1 系列中的 32B 参数深度推理模型，针对需要长时间思考的复杂、开放式任务进行了优化。它建立在 glm-4-32b-0414 的基础上，增加了额外的强化学习阶段和多阶段对齐策略，引入了旨在模拟扩展认知处理的“反思”能力。这包括迭代推理、多跳分析和工具增强的工作流程，例如搜索、检索和引文感知合成。\\n\\n该模型在研究式写作、比较分析和复杂问答方面表现出色。它支持用于搜索和导航原语（`search`、`click`、`open`、`finish`）的函数调用，从而可以在代理式管道中使用。反思行为由具有基于规则的奖励塑造和延迟决策机制的多轮循环控制，并以 OpenAI 内部对齐堆栈等深度研究框架为基准。此变体适用于需要深度而非速度的场景。",
    "ai21-jamba-1.5-large": "一个398B参数（94B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。",
    "Qwen/QwQ-32B-Preview": "Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。",
    "openai/o4-mini-high": "o4-mini 高推理等级版，专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。",
    "qwen-math-turbo-latest": "通义千问数学模型是专门用于数学解题的语言模型。",
    "Pro/Qwen/Qwen2.5-Coder-7B-Instruct": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
    "THUDM/GLM-Z1-32B-0414": "GLM-Z1-32B-0414 是一个具有深度思考能力的推理模型。该模型基于 GLM-4-32B-0414 通过冷启动和扩展强化学习开发，并在数学、代码和逻辑任务上进行了进一步训练。与基础模型相比，GLM-Z1-32B-0414 显著提升了数学能力和解决复杂任务的能力。",
    "mistralai/Mistral-7B-Instruct-v0.2": "Mistral (7B) Instruct v0.2 提供改进的指令处理能力和更精确的结果。",
    "hunyuan-turbos-vision": "此模型适用于图文理解场景，是基于混元最新 turbos 的新一代视觉语言旗舰大模型，聚焦图文理解相关任务，包括基于图片的实体识别、知识问答、文案创作、拍照解题等方面，相比前一代模型全面提升。",
    "c4ai-aya-expanse-32b": "Aya Expanse 是一款高性能的 32B 多语言模型，旨在通过指令调优、数据套利、偏好训练和模型合并的创新，挑战单语言模型的表现。它支持 23 种语言。",
    "deepseek_r1_distill_qwen_32b": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。",
    "command-r7b-12-2024": "command-r7b-12-2024 是一个小型且高效的更新版本，于 2024 年 12 月发布。它在 RAG、工具使用、代理等需要复杂推理和多步处理的任务中表现出色。",
    "Qwen/Qwen2.5-VL-32B-Instruct": "Qwen2.5-VL-32B-Instruct 是通义千问团队推出的多模态大模型，是 Qwen2.5-VL 系列的一部分。该模型不仅精通识别常见物体，还能分析图像中的文本、图表、图标、图形和布局。它可作为视觉智能体，能够推理并动态操控工具，具备使用电脑和手机的能力。此外，这个模型可以精确定位图像中的对象，并为发票、表格等生成结构化输出。相比前代模型 Qwen2-VL，该版本在数学和问题解决能力方面通过强化学习得到了进一步提升，响应风格也更符合人类偏好。",
    "claude-3-5-haiku-20241022": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",
    "step-1v-8k": "小型视觉模型，适合基本的图文任务。",
    "databricks/dbrx-instruct": "DBRX Instruct 提供高可靠性的指令处理能力，支持多行业应用。",
    "qwen3-30b-a3b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "hunyuan-turbo-latest": "通用体验优化，包括NLP理解、文本创作、闲聊、知识问答、翻译、领域等；提升拟人性，优化模型情商；提升意图模糊时模型主动澄清能力；提升字词解析类问题的处理能力；提升创作的质量和可互动性；提升多轮体验。",
    "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": "Meta 推出的指令微调图像推理模型，拥有 900 亿参数。该模型针对视觉识别、图像推理、图片字幕生成以及图片相关的常规问答进行了优化。它能够理解视觉数据，如图表和图形，并通过生成文本描述图像细节，弥合视觉与语言之间的鸿沟。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。",
    "codellama/CodeLlama-34b-Instruct-hf": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。",
    "Doubao-pro-256k": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 256k 上下文窗口的推理和精调。",
    "ERNIE-4.0-Turbo-8K-Preview": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀",
    "ernie-char-8k": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。",
    "glm-z1-flash": "GLM-Z1 系列具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。最大上下文长度为32K。",
    "openai/gpt-4.1": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。",
    "Doubao-vision-lite-32k": "Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。",
    "qwen-vl-plus-latest": "通义千问大规模视觉语言模型增强版。大幅提升细节识别能力和文字识别能力，支持超百万像素分辨率和任意长宽比规格的图像。",
    "qwen-omni-turbo-latest": "Qwen-Omni 系列模型支持输入多种模态的数据，包括视频、音频、图片、文本，并输出音频与文本。",
    "ERNIE-3.5-8K-Preview": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。",
    "Qwen/Qwen3-8B": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "ERNIE-Speed-Pro-128K": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，效果比ERNIE Speed更优，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。",
    "glm-4-flashx": "GLM-4-FlashX 是Flash的增强版本，超快推理速度。",
    "gpt-4.1-mini": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。",
    "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": "DeepSeek-R1-Distill-Qwen-1.5B 是基于 Qwen2.5-Math-1.5B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在多个基准测试中展现出不错的性能。作为一个轻量级模型，在 MATH-500 上达到了 83.9% 的准确率，在 AIME 2024 上达到了 28.9% 的通过率，在 CodeForces 上获得了 954 的评分，显示出超出其参数规模的推理能力。",
    "deepseek/deepseek-r1": "DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。",
    "meta-llama/Llama-3-70b-chat-hf": "Llama 3 70B Instruct Reference 是功能强大的聊天模型，支持复杂的对话需求。",
    "sonar": "基于搜索上下文的轻量级搜索产品，比 Sonar Pro 更快、更便宜。",
    "chatgpt-4o-latest": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "meta.llama3-1-405b-instruct-v1:0": "Meta Llama 3.1 405B Instruct 是 Llama 3.1 Instruct 模型中最大、最强大的模型，是一款高度先进的对话推理和合成数据生成模型，也可以用作在特定领域进行专业持续预训练或微调的基础。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。",
    "claude-2.0": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。",
    "hunyuan-turbo": "混元全新一代大语言模型的预览版，采用全新的混合专家模型（MoE）结构，相比hunyuan-pro推理效率更快，效果表现更强。",
    "gpt-4.5-preview": "GPT-4.5 的研究预览版，它是我们迄今为止最大、最强大的 GPT 模型。它拥有广泛的世界知识，并能更好地理解用户意图，使其在创造性任务和自主规划方面表现出色。GPT-4.5 可接受文本和图像输入，并生成文本输出（包括结构化输出）。支持关键的开发者功能，如函数调用、批量 API 和流式输出。在需要创造性、开放式思考和对话的任务（如写作、学习或探索新想法）中，GPT-4.5 表现尤为出色。知识截止日期为 2023 年 10 月。",
    "deepseek-ai/DeepSeek-V3": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
    "anthropic/claude-3.5-sonnet": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
    "QwQ-32B-Preview": "Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。",
    "internlm3-latest": "我们最新的模型系列，有着卓越的推理性能，领跑同量级开源模型。默认指向我们最新发布的 InternLM3 系列模型，当前指向 internlm3-8b-instruct。",
    "Doubao-1.5-thinking-vision-pro": "全新视觉深度思考模型，具备更强的通用多模态理解和推理能力，在 59 个公开评测基准中的 37 个上取得 SOTA 表现。",
    "learnlm-2.0-flash-experimental": "LearnLM 是一个实验性的、特定于任务的语言模型，经过训练以符合学习科学原则，可在教学和学习场景中遵循系统指令，充当专家导师等。",
    "aya": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，为多元化语言应用提供便利。",
    "accounts/fireworks/models/llama-v3p1-8b-instruct": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 三种参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话应用优化，并在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。",
    "Doubao-1.5-thinking-pro-m": "Doubao-1.5全新深度思考模型 (m 版本自带原生多模态深度推理能力)，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。",
    "mistralai/Mistral-7B-v0.1": "Mistral 7B是一款紧凑但高性能的模型，擅长批量处理和简单任务，如分类和文本生成，具有良好的推理能力。",
    "qwen/qwen3-14b:free": "Qwen3-14B 是 Qwen3 系列中一个密集的 148 亿参数因果语言模型，专为复杂推理和高效对话而设计。它支持在用于数学、编程和逻辑推理等任务的“思考”模式与用于通用对话的“非思考”模式之间无缝切换。该模型经过微调，可用于指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。",
    "gpt-4o-2024-05-13": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "Pro/deepseek-ai/DeepSeek-V3-1226": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
    "glm-4-long": "GLM-4-Long 支持超长文本输入，适合记忆型任务与大规模文档处理。",
    "anthropic.claude-v2:1": "Claude 2 的更新版，具有双倍的上下文窗口，以及在长文档和 RAG 上下文中的可靠性、幻觉率和基于证据的准确性的改进。",
    "llama-3.3-instruct": "Llama 3.3 指令微调模型针对对话场景进行了优化，在常见的行业基准测试中，超越了许多现有的开源聊天模型。",
    "charglm-4": "CharGLM-4 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。",
    "Qwen2.5-14B-Instruct": "通义千问2.5对外开源的14B规模的模型。",
    "gemini-1.5-flash-8b-exp-0924": "Gemini 1.5 Flash 8B 0924 是最新的实验性模型，在文本和多模态用例中都有显著的性能提升。",
    "c4ai-aya-expanse-8b": "Aya Expanse 是一款高性能的 8B 多语言模型，旨在通过指令调优、数据套利、偏好训练和模型合并的创新，挑战单语言模型的表现。它支持 23 种语言。",
    "glm-4v": "GLM-4V 提供强大的图像理解与推理能力，支持多种视觉任务。",
    "glm-4v-plus-0111": "GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。",
    "Phi-3-small-8k-instruct": "一个70亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。",
    "glm-z1-airx": "极速推理：具有超快的推理速度和强大的推理效果。",
    "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": "Llama 3 8B Instruct Turbo 是一款高效能的大语言模型，支持广泛的应用场景。",
    "deepseek-chat": "融合通用与代码能力的全新开源模型, 不仅保留了原有 Chat 模型的通用对话能力和 Coder 模型的强大代码处理能力，还更好地对齐了人类偏好。此外，DeepSeek-V2.5 在写作任务、指令跟随等多个方面也实现了大幅提升。",
    "deepseek/deepseek-r1-distill-llama-8b": "DeepSeek R1 Distill Llama 8B 是一种基于 Llama-3.1-8B-Instruct 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。",
    "deepseek/deepseek-v3": "DeepSeek-V3在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。",
    "thudm/glm-z1-32b:free": "GLM-Z1-32B-0414 是 GLM-4-32B 的增强推理变体，专为深度数学、逻辑和面向代码的问题解决而构建。它应用扩展强化学习（任务特定和基于通用成对偏好）来提高复杂多步骤任务的性能。与基础 GLM-4-32B 模型相比，Z1 显著提升了结构化推理和形式化领域的能力。\\n\\n该模型支持通过提示工程强制执行“思考”步骤，并为长格式输出提供改进的连贯性。它针对代理工作流进行了优化，并支持长上下文（通过 YaRN）、JSON 工具调用和用于稳定推理的细粒度采样配置。非常适合需要深思熟虑、多步骤推理或形式化推导的用例。",
    "codegeex4-all-9b": "CodeGeeX4-ALL-9B 是一个多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。",
    "google/gemma-3-27b-it": "Gemma 3 27B 是谷歌的一款开源语言模型，以其在效率和性能方面设立了新的标准。",
    "hunyuan-functioncall": "混元最新 MOE 架构 FunctionCall 模型，经过高质量的 FunctionCall 数据训练，上下文窗口达 32K，在多个维度的评测指标上处于领先。",
    "deepseek-r1-fast-online": "DeepSeek R1 满血快速版，支持实时联网搜索，结合了 671B 参数的强大能力和更快的响应速度。",
    "internvl3-latest": "我们最新发布多模态大模型，具备更强的图文理解能力、长时序图片理解能力，性能比肩顶尖闭源模型。默认指向我们最新发布的 InternVL 系列模型，当前指向 internvl3-78b。",
    "qwen3-14b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "o3": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。",
    "hunyuan-turbos-longtext-128k-20250325": "擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。",
    "nvidia/llama-3.1-nemotron-70b-instruct": "Llama-3.1-Nemotron-70B-Instruct 是 NVIDIA 定制的大型语言模型，旨在提高 LLM 生成的响应的帮助性。",
    "anthropic.claude-v2": "Anthropic 在从复杂对话和创意内容生成到详细指令跟随的广泛任务中都表现出高度能力的模型。",
    "SenseChat-5-beta": "部分性能优于 SenseCat-5-1202",
    "deepseek-r1-distill-qianfan-llama-8b": "2025年2月14日首次发布，由千帆大模型研发团队以 Llama3_8B为base模型（Built with Meta Llama）蒸馏所得，蒸馏数据中也同步添加了千帆的语料。",
    "command-r-plus-04-2024": "command-r-plus 是 command-r-plus-04-2024 的别名，因此如果您在 API 中使用 command-r-plus，实际上指向的就是该模型。",
    "openai/o3-mini": "o3-mini 在与 o1-mini 相同的成本和延迟目标下提供高智能。",
    "deepseek/deepseek-chat": "融合通用与代码能力的全新开源模型, 不仅保留了原有 Chat 模型的通用对话能力和 Coder 模型的强大代码处理能力，还更好地对齐了人类偏好。此外，DeepSeek-V2.5 在写作任务、指令跟随等多个方面也实现了大幅提升。",
    "llama-3.2-11b-vision-instruct": "在高分辨率图像上表现出色的图像推理能力，适用于视觉理解应用。",
    "generalv3": "Spark Pro 是一款为专业领域优化的高性能大语言模型，专注数学、编程、医疗、教育等多个领域，并支持联网搜索及内置天气、日期等插件。其优化后模型在复杂知识问答、语言理解及高层次文本创作中展现出色表现和高效性能，是适合专业应用场景的理想选择。",
    "chatglm3": "ChatGLM3 是智谱 AI 与清华 KEG 实验室发布的闭源模型，经过海量中英标识符的预训练与人类偏好对齐训练，相比一代模型在 MMLU、C-Eval、GSM8K 分别取得了 16%、36%、280% 的提升，并登顶中文任务榜单 C-Eval。适用于对知识量、推理能力、创造力要求较高的场景，比如广告文案、小说写作、知识类写作、代码生成等。",
    "hunyuan-t1-20250321": "全面搭建模型文理科能力，长文本信息捕捉能力强。支持推理解答各种难度的数学/逻辑推理/科学/代码等科学问题。",
    "meta/llama-3.1-70b-instruct": "赋能复杂对话，具备卓越的上下文理解、推理能力和文本生成能力。",
    "hunyuan-standard": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-32K 性价比相对更高，在平衡效果、价格的同时，可对实现对长文本输入的处理。",
    "meta-llama-3-8b-instruct": "一个多功能的80亿参数模型，针对对话和文本生成任务进行了优化。",
    "qwen2": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "Baichuan4": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。",
    "Phi-3-medium-4k-instruct": "一个140亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。",
    "deepseek/deepseek-chat-v3-0324": "DeepSeek V3 是一个 685B 参数的专家混合模型，是 DeepSeek 团队旗舰聊天模型系列的最新迭代。\\n\\n它继承了 [DeepSeek V3](/deepseek/deepseek-chat-v3) 模型，并在各种任务上表现出色。",
    "Doubao-1.5-vision-pro": "Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。",
    "Baichuan4-Turbo": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。",
    "Skylark2-lite-8k": "云雀（Skylark）第二代模型，Skylark2-lite模型有较高的响应速度，适用于实时性要求高、成本敏感、对模型精度要求不高的场景，上下文窗口长度为8k。",
    "text-embedding-3-large": "最强大的向量化模型，适用于英文和非英文任务",
    "qwen2.5-math-1.5b-instruct": "Qwen-Math 模型具有强大的数学解题能力。",
    "llava:13b": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。",
    "hunyuan-standard-vision": "混元最新多模态模型，支持多语种作答，中英文能力均衡。",
    "glm-4-plus": "GLM-4-Plus 作为高智能旗舰，具备强大的处理长文本和复杂任务的能力，性能全面提升。",
    "thudm/glm-z1-32b": "GLM-Z1-32B-0414 是 GLM-4-32B 的增强推理变体，专为深度数学、逻辑和面向代码的问题解决而构建。它应用扩展强化学习（任务特定和基于通用成对偏好）来提高复杂多步骤任务的性能。与基础 GLM-4-32B 模型相比，Z1 显著提升了结构化推理和形式化领域的能力。\\n\\n该模型支持通过提示工程强制执行“思考”步骤，并为长格式输出提供改进的连贯性。它针对代理工作流进行了优化，并支持长上下文（通过 YaRN）、JSON 工具调用和用于稳定推理的细粒度采样配置。非常适合需要深思熟虑、多步骤推理或形式化推导的用例。",
    "gpt-4o-realtime-preview-2024-12-17": "GPT-4o 实时版本，支持音频和文本实时输入输出",
    "llama-3.2-90b-vision-preview": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "codegeex-4": "CodeGeeX-4 是强大的AI编程助手，支持多种编程语言的智能问答与代码补全，提升开发效率。",
    "abab5.5-chat": "面向生产力场景，支持复杂任务处理和高效文本生成，适用于专业领域应用。",
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。",
    "claude-3-5-sonnet-20241022": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
    "meta-llama-3-70b-instruct": "一个强大的700亿参数模型，在推理、编码和广泛的语言应用方面表现出色。",
    "anthropic/claude-3-opus": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。",
    "meta.llama3-1-8b-instruct-v1:0": "Meta Llama 3.1 8B Instruct 的更新版，包括扩展的 128K 上下文长度、多语言性和改进的推理能力。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。",
    "ernie-4.0-turbo-128k": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀",
    "meta/llama-3.2-1b-instruct": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。",
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": "Claude 3.7 sonnet 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.7 Sonnet 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",
    "mistralai/Mixtral-8x7B-v0.1": "Mixtral 8x7B是一个稀疏专家模型，利用多个参数提高推理速度，适合处理多语言和代码生成任务。",
    "qwen2.5": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "glm-z1-air": "推理模型: 具备强大推理能力，适用于需要深度推理的任务。",
    "mistral-large-latest": "Mistral Large是旗舰大模型，擅长多语言任务、复杂推理和代码生成，是高端应用的理想选择。",
    "hunyuan-role": "混元最新版角色扮演模型，混元官方精调训练推出的角色扮演模型，基于混元模型结合角色扮演场景数据集进行增训，在角色扮演场景具有更好的基础效果。",
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": "405B 的 Llama 3.1 Turbo 模型，为大数据处理提供超大容量的上下文支持，在超大规模的人工智能应用中表现突出。",
    "meta-llama/llama-3.2-11b-vision-instruct": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "glm-4-air-250414": "GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。",
    "Doubao-pro-32k": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 32k 上下文窗口的推理和精调。",
    "qwen2.5-omni-7b": "Qwen-Omni 系列模型支持输入多种模态的数据，包括视频、音频、图片、文本，并输出音频与文本。",
    "meta/llama-3.3-70b-instruct": "先进的 LLM，擅长推理、数学、常识和函数调用。",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。在 AIME 2024、MATH-500、GPQA Diamond 等多个基准测试中都取得了优异成绩，其中在 MATH-500 上达到了 94.3% 的准确率，展现出强大的数学推理能力。",
    "gemma2:2b": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。",
    "gpt-4-32k": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
    "phi3": "Phi-3 是微软推出的轻量级开放模型，适用于高效集成和大规模知识推理。",
    "google/gemma-2-2b-it": "面向边缘应用的高级小型语言生成 AI 模型。",
    "deepseek-r1-distill-llama": "deepseek-r1-distill-llama 是基于 Llama 从 DeepSeek-R1 蒸馏而来的模型。",
    "hunyuan-t1-latest": "业内首个超大规模 Hybrid-Transformer-Mamba 推理模型，扩展推理能力，超强解码速度，进一步对齐人类偏好。",
    "deepseek/deepseek-r1-distill-qwen-14b": "DeepSeek R1 Distill Qwen 14B 是一种基于 Qwen 2.5 14B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nCodeForces Rating: 1481\\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。",
    "codellama:34b": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。",
    "open-mistral-nemo": "Mistral Nemo是一个与Nvidia合作开发的12B模型，提供出色的推理和编码性能，易于集成和替换。",
    "llama3-70b-8192": "Meta Llama 3 70B 提供无与伦比的复杂性处理能力，为高要求项目量身定制。",
    "deepseek-ai/deepseek-llm-67b-chat": "DeepSeek LLM Chat (67B) 是创新的 AI 模型 提供深度语言理解和互动能力。",
    "Pro/Qwen/Qwen2-1.5B-Instruct": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
    "hunyuan-large-longcontext": "擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。",
    "Doubao-1.5-vision-pro-32k": "Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。",
    "mistral-small-latest": "Mistral Small是成本效益高、快速且可靠的选项，适用于翻译、摘要和情感分析等用例。",
    "yi-large-fc": "在 yi-large 模型的基础上支持并强化了工具调用的能力，适用于各种需要搭建 agent 或 workflow 的业务场景。",
    "sonar-reasoning": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。",
    "Qwen2-VL-72B": "Qwen2-VL-72B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
    "Pro/Qwen/Qwen2-VL-7B-Instruct": "Qwen2-VL-7B-Instruct 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够用于高质量的基于视频的问答、对话和内容创作，还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
    "qwen2.5:72b": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "grok-vision-beta": "最新的图像理解模型，可以处理各种各样的视觉信息，包括文档、图表、截图和照片等。",
    "phi3:14b": "Phi-3 是微软推出的轻量级开放模型，适用于高效集成和大规模知识推理。",
    "google/gemma-2-27b-it": "Gemma 2 27B 是一款通用大语言模型，具有优异的性能和广泛的应用场景。",
    "baichuan/baichuan2-13b-chat": "Baichuan-13B 百川智能开发的包含 130 亿参数的开源可商用的大规模语言模型，在权威的中文和英文 benchmark 上均取得同尺寸最好的效果",
    "doubao-1.5-lite-32k": "Doubao-1.5-lite 全新一代轻量版模型，极致响应速度，效果与时延均达到全球一流水平。",
    "abab6.5g-chat": "专为多语种人设对话设计，支持英文及其他多种语言的高质量对话生成。",
    "command-r-08-2024": "command-r-08-2024 是 Command R 模型的更新版本，于 2024 年 8 月发布。",
    "Doubao-pro-4k": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 4k 上下文窗口的推理和精调。",
    "Phi-3-medium-128k-instruct": "相同的Phi-3-medium模型，但具有更大的上下文大小，适用于RAG或少量提示。",
    "meta-llama-3.1-405b-instruct": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
    "deepseek/deepseek-r1-distill-llama-70b": "DeepSeek R1 Distill Llama 70B是基于Llama3.3  70B的大型语言模型，该模型利用DeepSeek R1输出的微调，实现了与大型前沿模型相当的竞争性能。",
    "Pro/Qwen/Qwen2.5-VL-7B-Instruct": "Qwen2.5-VL 是 Qwen 系列的新成员，具备强大的视觉理解能力，能分析图像中的文本、图表和布局，并能理解长视频和捕捉事件，它可以进行推理、操作工具，支持多格式物体定位和生成结构化输出，优化了视频理解的动态分辨率与帧率训练，并提升了视觉编码器效率。",
    "deepseek-coder-33B-instruct": "DeepSeek Coder 33B 是一个代码语言模型， 基于 2 万亿数据训练而成，其中 87% 为代码， 13% 为中英文语言。模型引入 16K 窗口大小和填空任务，提供项目级别的代码补全和片段填充功能。",
    "generalv3.5": "Spark Max 为功能最为全面的版本，支持联网搜索及众多内置插件。其全面优化的核心能力以及系统角色设定和函数调用功能，使其在各种复杂应用场景中的表现极为优异和出色。",
    "qwen/qwen2.5-7b-instruct": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "accounts/fireworks/models/llama-v3-70b-instruct": "Meta 开发并发布了 Meta Llama 3 系列大语言模型（LLM），该系列包含 8B 和 70B 参数规模的预训练和指令微调生成文本模型。Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。",
    "hunyuan-turbo-20241223": "本版本优化：数据指令scaling，大幅提升模型通用泛化能力；大幅提升数学、代码、逻辑推理能力；优化文本理解字词理解相关能力；优化文本创作内容生成质量",
    "qwq-32b": "QwQ 是 Qwen 系列的推理模型。与传统的指令微调模型相比，QwQ 具备思考和推理能力，在下游任务中，尤其是复杂问题上，能够实现显著增强的性能。QwQ-32B 是一款中型推理模型，其性能可与最先进的推理模型（如 DeepSeek-R1、o1-mini）相媲美。",
    "mistralai/Mistral-7B-Instruct-v0.3": "Mistral (7B) Instruct v0.3 提供高效的计算能力和自然语言理解，适合广泛的应用。",
    "qwen-vl-max-latest": "通义千问超大规模视觉语言模型。相比增强版，再次提升视觉推理能力和指令遵循能力，提供更高的视觉感知和认知水平。",
    "SenseChat": "基础版本模型 (V4)，4K上下文长度，通用能力强大",
    "SenseChat-Turbo-1202": "是最新的轻量版本模型，达到全量模型90%以上能力，显著降低推理成本。",
    "amazon.titan-text-express-v1": "亚马逊 Titan Text Express 的上下文长度可达 8,000 个标记，非常适合广泛的高级通用语言任务，如开放式文本生成和对话聊天，以及在检索增强生成 (RAG) 中的支持。在推出时，该模型针对英语进行了优化，预览版还支持其他 100 多种语言。",
    "meta-llama/Meta-Llama-3-8B-Instruct-Lite": "Llama 3 8B Instruct Lite 适合资源受限的环境，提供出色的平衡性能。",
    "hunyuan-turbos-latest": "hunyuan-TurboS 混元旗舰大模型最新版本，具备更强的思考能力，更优的体验效果。",
    "taichu_llm": "基于海量高质数据训练，具有更强的文本理解、内容创作、对话问答等能力",
    "yi-large-rag": "基于 yi-large 超强模型的高阶服务，结合检索与生成技术提供精准答案，实时全网检索信息服务。",
    "o1-preview": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。",
    "aya:35b": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，为多元化语言应用提供便利。",
    "tngtech/deepseek-r1t-chimera:free": "DeepSeek-R1T-Chimera 通过合并 DeepSeek-R1 和 DeepSeek-V3 (0324) 创建，结合了 R1 的推理能力和 V3 的令牌效率改进。它基于 DeepSeek-MoE Transformer 架构，并针对通用文本生成任务进行了优化。\\n\\n该模型合并了两个源模型的预训练权重，以平衡推理、效率和指令遵循任务的性能。它根据 MIT 许可证发布，旨在用于研究和商业用途。",
    "deepseek/deepseek-chat-v3-0324:free": "DeepSeek V3 是一个 685B 参数的专家混合模型，是 DeepSeek 团队旗舰聊天模型系列的最新迭代。\\n\\n它继承了 [DeepSeek V3](/deepseek/deepseek-chat-v3) 模型，并在各种任务上表现出色。",
    "command-r": "Command R 是优化用于对话和长上下文任务的LLM，特别适合动态交互与知识管理。",
    "meta.llama3-8b-instruct-v1:0": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放大型语言模型 (LLM)，旨在帮助他们构建、实验并负责任地扩展他们的生成 AI 想法。作为全球社区创新的基础系统的一部分，它非常适合计算能力和资源有限、边缘设备和更快的训练时间。",
    "qwen-long": "通义千问超大规模语言模型，支持长文本上下文，以及基于长文档、多文档等多个场景的对话功能。",
    "mixtral:8x22b": "Mixtral 是 Mistral AI 的专家模型，具有开源权重，并在代码生成和语言理解方面提供支持。",
    "anthropic.claude-3-haiku-20240307-v1:0": "Claude 3 Haiku 是 Anthropic 最快、最紧凑的模型，提供近乎即时的响应速度。它可以快速回答简单的查询和请求。客户将能够构建模仿人类互动的无缝 AI 体验。Claude 3 Haiku 可以处理图像并返回文本输出，具有 200K 的上下文窗口。",
    "accounts/fireworks/models/deepseek-r1": "DeepSeek-R1 是一款最先进的大型语言模型，经过强化学习和冷启动数据的优化，具有出色的推理、数学和编程性能。",
    "Doubao-pro-128k": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 128k 上下文窗口的推理和精调。",
    "qwen-vl-ocr-latest": "通义千问OCR是文字提取专有模型，专注于文档、表格、试题、手写体文字等类型图像的文字提取能力。它能够识别多种文字，目前支持的语言有：汉语、英语、法语、日语、韩语、德语、俄语、意大利语、越南语、阿拉伯语。",
    "step-2-mini": "基于新一代自研Attention架构MFA的极速大模型，用极低成本达到和step1类似的效果，同时保持了更高的吞吐和更快响应时延。能够处理通用任务，在代码能力上具备特长。",
    "meta-llama/Llama-2-13b-chat-hf": "LLaMA-2 Chat (13B) 提供优秀的语言处理能力和出色的交互体验。",
    "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": "Llama 3.1 Nemotron 70B 是由 NVIDIA 定制的大型语言模型，旨在提高 LLM 生成的响应对用户查询的帮助程度。该模型在 Arena Hard、AlpacaEval 2 LC 和 GPT-4-Turbo MT-Bench 等基准测试中表现出色，截至 2024 年 10 月 1 日，在所有三个自动对齐基准测试中排名第一。该模型使用 RLHF（特别是 REINFORCE）、Llama-3.1-Nemotron-70B-Reward 和 HelpSteer2-Preference 提示在 Llama-3.1-70B-Instruct 模型基础上进行训练",
    "o3-mini": "o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。",
    "upstage/SOLAR-10.7B-Instruct-v1.0": "Upstage SOLAR Instruct v1 (11B) 适用于精细化指令任务，提供出色的语言处理能力。",
    "Phi-3-mini-128k-instruct": "相同的Phi-3-mini模型，但具有更大的上下文大小，适用于RAG或少量提示。",
    "gemma2:27b": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。",
    "step-1-8k": "小型模型，适合轻量级任务。",
    "Pro/deepseek-ai/DeepSeek-R1": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。",
    "accounts/fireworks/models/mixtral-8x22b-instruct": "Mixtral MoE 8x22B Instruct v0.1 是 Mixtral MoE 8x22B v0.1 的指令微调版本，已启用聊天完成功能 API。",
    "mistral-small": "Mistral Small可用于任何需要高效率和低延迟的基于语言的任务。",
    "command-nightly": "为了缩短主要版本发布之间的时间间隔，我们推出了 Command 模型的每夜版本。对于 Command 系列，这一版本称为 command-cightly。请注意，command-nightly 是最新、最具实验性且（可能）不稳定的版本。每夜版本会定期更新，且不会提前通知，因此不建议在生产环境中使用。",
    "glm-4-alltools": "GLM-4-AllTools 是一个多功能智能体模型，优化以支持复杂指令规划与工具调用，如网络浏览、代码解释和文本生成，适用于多任务执行。",
    "qwen/qwen3-14b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "llama-3.3-70b-versatile": "Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。",
    "nvidia/llama-3.1-nemotron-51b-instruct": "独特的语言模型，提供无与伦比的准确性和效率表现。",
    "Qwen/Qwen2.5-72B-Instruct-128K": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的输入，可以生成超过 8K tokens 的长文本。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "Baichuan3-Turbo-128k": "具备 128K 超长上下文窗口，针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。",
    "deepseek_r1": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。",
    "meta-llama-3.1-8b-instruct": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
    "deepseek-r1-70b-online": "DeepSeek R1 70B 标准版，支持实时联网搜索，适合需要最新信息的对话和文本处理任务。",
    "InternVL2-8B": "InternVL2-8B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
    "doubao-1.5-pro-32k": "Doubao-1.5-pro 全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。",
    "mistral-nemo": "Mistral Nemo 由 Mistral AI 和 NVIDIA 合作推出，是高效性能的 12B 模型。",
    "SenseChat-Vision": "最新版本模型 (V5.5)，支持多图的输入，全面实现模型基础能力优化，在对象属性识别、空间关系、动作事件识别、场景理解、情感识别、逻辑常识推理和文本理解生成上都实现了较大提升。",
    "Meta-Llama-3.2-3B-Instruct": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。",
    "qwen2.5-vl-7b-instruct": "指令跟随、数学、解题、代码整体提升，万物识别能力提升，支持多样格式直接精准定位视觉元素，支持对长视频文件（最长10分钟）进行理解和秒级别的事件时刻定位，能理解时间先后和快慢，基于解析和定位能力支持操控OS或Mobile的Agent，关键信息抽取能力和Json格式输出能力强，此版本为72B版本，本系列能力最强的版本。",
    "hunyuan-lite": "升级为 MOE 结构，上下文窗口为 256k ，在 NLP，代码，数学，行业等多项评测集上领先众多开源模型。",
    "pro-128k": "Spark Pro 128K 配置了特大上下文处理能力，能够处理多达128K的上下文信息，特别适合需通篇分析和长期逻辑关联处理的长文内容，可在复杂文本沟通中提供流畅一致的逻辑与多样的引用支持。",
    "mistral": "Mistral 是 Mistral AI 发布的 7B 模型，适合多变的语言处理需求。",
    "Qwen2-7B-Instruct": "Qwen2 是 Qwen 团队推出的新一代大型语言模型系列。它基于 Transformer 架构，并采用 SwiGLU 激活函数、注意力 QKV 偏置(attention QKV bias)、群组查询注意力(group query attention)、滑动窗口注意力(mixture of sliding window attention)与全注意力的混合等技术。此外，Qwen 团队还改进了适应多种自然语言和代码的分词器。",
    "google/gemma-2-9b": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。",
    "gpt-4.1": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。",
    "anthropic.claude-instant-v1": "一款快速、经济且仍然非常有能力的模型，可以处理包括日常对话、文本分析、总结和文档问答在内的一系列任务。",
    "gpt-4o-2024-11-20": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "jina-deepsearch-v1": "深度搜索结合了网络搜索、阅读和推理，可进行全面调查。您可以将其视为一个代理，接受您的研究任务 - 它会进行广泛搜索并经过多次迭代，然后才能给出答案。这个过程涉及持续的研究、推理和从各个角度解决问题。这与直接从预训练数据生成答案的标准大模型以及依赖一次性表面搜索的传统 RAG 系统有着根本的不同。",
    "glm-4-air": "GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。",
    "abab6.5t-chat": "针对中文人设对话场景优化，提供流畅且符合中文表达习惯的对话生成能力。",
    "meta-llama/llama-3.3-70b-instruct": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月",
    "ernie-char-fiction-8k": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。",
    "Doubao-lite-4k": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 4k 上下文窗口的推理和精调。",
    "claude-2.1": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。",
    "accounts/fireworks/models/phi-3-vision-128k-instruct": "Phi-3-Vision-128K-Instruct 是一个轻量级的、最先进的开放多模态模型，基于包括合成数据和筛选后的公开网站数据集构建，重点关注文本和视觉方面的高质量、推理密集型数据。该模型属于 Phi-3 模型家族，其多模态版本支持 128K 上下文长度（以标记为单位）。该模型经过严格的增强过程，包括监督微调和直接偏好优化，以确保精确的指令遵循和强大的安全措施。",
    "grok-3-mini-fast-beta": "轻量级模型，回话前会先思考。运行快速、智能，适用于不需要深层领域知识的逻辑任务，并能获取原始的思维轨迹。",
    "openai/o3": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。",
    "accounts/fireworks/models/deepseek-v3": "Deepseek 提供的强大 Mixture-of-Experts (MoE) 语言模型，总参数量为 671B，每个标记激活 37B 参数。",
    "meta/llama-3.1-8b-instruct": "先进的最尖端模型，具备语言理解、卓越的推理能力和文本生成能力。",
    "google/gemma-2-9b-it:free": "Gemma 2 是Google轻量化的开源文本模型系列。",
    "yi-vision": "复杂视觉任务模型，提供高性能图片理解、分析能力。",
    "doubao-1.5-pro-256k": "Doubao-1.5-pro-256k 基于 Doubao-1.5-Pro 全面升级版，整体效果大幅提升 10%。支持 256k 上下文窗口的推理，输出长度支持最大 12k tokens。更高性能、更大窗口、超高性价比，适用于更广泛的应用场景。",
    "max-32k": "Spark Max 32K 配置了大上下文处理能力，更强的上下文理解和逻辑推理能力，支持32K tokens的文本输入，适用于长文档阅读、私有知识问答等场景",
    "qwen2.5-math-72b-instruct": "Qwen-Math 模型具有强大的数学解题能力。",
    "claude-3-7-sonnet-20250219": "Claude 3.7 Sonnet 是 Anthropic 迄今为止最智能的模型，也是市场上首个混合推理模型。Claude 3.7 Sonnet 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
    "moonshot-v1-32k-vision-preview": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。",
    "qvq-max-latest": "通义千问QVQ视觉推理模型，支持视觉输入及思维链输出，在数学、编程、视觉分析、创作以及通用任务上都表现了更强的能力。",
    "step-2-16k-exp": "step-2模型的实验版本，包含最新的特性，滚动更新中。不推荐在正式生产环境使用。",
    "r1-1776": "R1-1776 是 DeepSeek R1 模型的一个版本，经过后训练，可提供未经审查、无偏见的事实信息。",
    "megrez-3b-instruct": "Megrez-3B-Instruct 是由无问芯穹完全自主训练的大语言模型。Megrez-3B-Instruct 旨在通过软硬协同理念，打造一款极速推理、小巧精悍、极易上手的端侧智能解决方案。",
    "meta-llama/llama-3-8b-instruct": "Llama 3 8B Instruct 优化了高质量对话场景，性能优于许多闭源模型。",
    "step-1-32k": "支持中等长度的对话，适用于多种应用场景。",
    "gemini-2.0-flash-exp": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。",
    "yi-large": "全新千亿参数模型，提供超强问答及文本生成能力。",
    "gemini-2.0-flash": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。",
    "grok-3-fast-beta": "旗舰级模型，擅长数据提取、编程和文本摘要等企业级应用，拥有金融、医疗、法律和科学等领域的深厚知识。",
    "qwen-max-latest": "通义千问千亿级别超大规模语言模型，支持中文、英文等不同语言输入，当前通义千问2.5产品版本背后的API模型。",
    "accounts/fireworks/models/llama-v3p1-405b-instruct": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话场景优化，在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。405B 是 Llama 3.1 家族中能力最强的模型。该模型采用 FP8 进行推理，与参考实现高度匹配。",
    "gryphe/mythomax-l2-13b": "MythoMax-L2 (13B) 是一种创新模型，适合多领域应用和复杂任务。",
    "gpt-3.5-turbo": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
    "abab5.5s-chat": "专为中文人设对话场景设计，提供高质量的中文对话生成能力，适用于多种应用场景。",
    "meta-llama/Llama-3.2-3B-Instruct-Turbo": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "Phi-3.5-vision-instrust": "Phi-3-vision模型的更新版。",
    "deepseek-r1-distill-qwen": "deepseek-r1-distill-qwen 是基于 Qwen 从 DeepSeek-R1 蒸馏而来的模型。",
    "360gpt-pro": "360GPT Pro 作为 360 AI 模型系列的重要成员，以高效的文本处理能力满足多样化的自然语言应用场景，支持长文本理解和多轮对话等功能。",
    "qwen2.5-coder-1.5b-instruct": "通义千问代码模型开源版。",
    "qwen2.5-14b-instruct-1m": "通义千问2.5对外开源的72B规模的模型。",
    "qwen2:72b": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "solar-mini": "Solar Mini 是一种紧凑型 LLM，性能优于 GPT-3.5，具备强大的多语言能力，支持英语和韩语，提供高效小巧的解决方案。",
    "o1": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。",
    "ERNIE-4.0-8K-Preview": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。",
    "gemini-2.5-pro-preview-05-06": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。",
    "qwen-vl-chat-v1": "通义千问VL支持灵活的交互方式，包括多图、多轮问答、创作等能力的模型。",
    "gpt-4-1106-preview": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
    "gpt-35-turbo-16k": "GPT 3.5 Turbo 16k，高容量文本生成模型，适合复杂任务。",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。",
    "tts-1": "最新的文本转语音模型，针对实时场景优化速度",
    "qwen2:1.5b": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "accounts/fireworks/models/qwen2-vl-72b-instruct": "Qwen-VL 模型的 72B 版本是阿里巴巴最新迭代的成果，代表了近一年的创新。",
    "Qwen/Qwen2.5-72B-Instruct-Turbo": "Qwen2.5 是全新的大型语言模型系列，旨在优化指令式任务的处理。",
    "step-1-256k": "具备超长上下文处理能力，尤其适合长文档分析。",
    "wizardlm2:8x22b": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。",
    "c4ai-aya-vision-32b": "Aya Vision 是一款最先进的多模态模型，在语言、文本和图像能力的多个关键基准上表现出色。它支持 23 种语言。这个 320 亿参数的版本专注于最先进的多语言表现。",
    "Doubao-vision-pro-32k": "Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。",
    "open-codestral-mamba": "Codestral Mamba是专注于代码生成的Mamba 2语言模型，为先进的代码和推理任务提供强力支持。",
    "learnlm-1.5-pro-experimental": "LearnLM 是一个实验性的、特定于任务的语言模型，经过训练以符合学习科学原则，可在教学和学习场景中遵循系统指令，充当专家导师等。",
    "qwq": "QwQ 是 Qwen 系列的推理模型。与传统的指令调优模型相比，QwQ 具备思考和推理的能力，能够在下游任务中，尤其是困难问题上，显著提升性能。QwQ-32B 是中型推理模型，能够在与最先进的推理模型（如 DeepSeek-R1、o1-mini）竞争时取得可观的表现。",
    "gemma-7b-it": "Gemma 7B 适合中小规模任务处理，兼具成本效益。",
    "Baichuan2-Turbo": "采用搜索增强技术实现大模型与领域知识、全网知识的全面链接。支持PDF、Word等多种文档上传及网址输入，信息获取及时、全面，输出结果准确、专业。",
    "yi-vision-v2": "复杂视觉任务模型，提供基于多张图片的高性能理解、分析能力。",
    "meta-llama/llama-3.3-70b-instruct:free": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月",
    "glm-4": "GLM-4 是发布于2024年1月的旧旗舰版本，目前已被更强的 GLM-4-0520 取代。",
    "claude-3-5-sonnet-20240620": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
    "mistralai/Mistral-7B-Instruct-v0.1": "Mistral (7B) Instruct 以高性能著称，适用于多种语言任务。",
    "ai21-jamba-1.5-mini": "一个52B参数（12B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。",
    "kimi-latest": "Kimi 智能助手产品使用最新的 Kimi 大模型，可能包含尚未稳定的特性。支持图片理解，同时会自动根据请求的上下文长度选择 8k/32k/128k 模型作为计费模型",
    "compound-beta": "Compound-beta 是一个复合 AI 系统，由 GroqCloud 中已经支持的多个开放可用的模型提供支持，可以智能地、有选择地使用工具来回答用户查询。",
    "claude-3-haiku-20240307": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。",
    "codellama:70b": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。",
    "google/gemini-flash-1.5": "Gemini 1.5 Flash 提供了优化后的多模态处理能力，适用多种复杂任务场景。",
    "c4ai-aya-vision-8b": "Aya Vision 是一款最先进的多模态模型，在语言、文本和图像能力的多个关键基准上表现出色。这个 80 亿参数的版本专注于低延迟和最佳性能。",
    "qwen3-32b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "openai/gpt-4.1-mini": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。",
    "hunyuan-vision": "混元最新多模态模型，支持图片+文本输入生成文本内容。",
    "lite": "Spark Lite 是一款轻量级大语言模型，具备极低的延迟与高效的处理能力，完全免费开放，支持实时在线搜索功能。其快速响应的特性使其在低算力设备上的推理应用和模型微调中表现出色，为用户带来出色的成本效益和智能体验，尤其在知识问答、内容生成及搜索场景下表现不俗。",
    "o4-mini": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。",
    "Qwen2.5-Coder-32B-Instruct": "高级 LLM，支持代码生成、推理和修复，涵盖主流编程语言。",
    "Pro/deepseek-ai/DeepSeek-V3": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
    "meta/llama-3.2-11b-vision-instruct": "尖端的视觉-语言模型，擅长从图像中进行高质量推理。",
    "gpt-4o-audio-preview": "GPT-4o Audio 模型，支持音频输入输出",
    "gpt-4o-mini": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。",
    "qwen3-4b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "anthropic/claude-3.7-sonnet": "Claude 3.7 Sonnet 是 Anthropic 迄今为止最智能的模型，也是市场上首个混合推理模型。Claude 3.7 Sonnet 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
    "wizardlm2": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。",
    "meta-llama/llama-3.2-3b-instruct": "meta-llama/llama-3.2-3b-instruct",
    "llama3-groq-8b-8192-tool-use-preview": "Llama 3 Groq 8B Tool Use 是针对高效工具使用优化的模型，支持快速并行计算。",
    "360gpt-pro-trans": "翻译专用模型，深度微调优化，翻译效果领先。",
    "code-raccoon-v1": "代码小浣熊是基于商汤大语言模型的软件智能研发助手，覆盖软件需求分析、架构设计、代码编写、软件测试等环节，满足用户代码编写、编程学习等各类需求。代码小浣熊支持 Python、Java、JavaScript、C++、Go、SQL 等 90+主流编程语言和 VS Code、IntelliJ IDEA 等主流 IDE。在实际应用中，代码小浣熊可帮助开发者提升编程效率超 50%。",
    "gpt-4-32k-0613": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
    "llama3-groq-70b-8192-tool-use-preview": "Llama 3 Groq 70B Tool Use 提供强大的工具调用能力，支持复杂任务的高效处理。",
    "qwen3-1.7b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "open-mixtral-8x7b": "Mixtral 8x7B是一个稀疏专家模型，利用多个参数提高推理速度，适合处理多语言和代码生成任务。",
    "Baichuan4-Air": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。",
    "ERNIE-3.5-128K": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。",
    "meta-llama/llama-3.1-8b-instruct:free": "LLaMA 3.1 提供多语言支持，是业界领先的生成模型之一。",
    "THUDM/GLM-4-32B-0414": "GLM-4-32B-0414 是 GLM 系列的新一代开源模型，拥有 320 亿参数。该模型性能可与 OpenAI 的 GPT 系列和 DeepSeek 的 V3/R1 系列相媲美。",
    "qwen-coder-plus-latest": "通义千问代码模型。",
    "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "text-embedding-3-small": "高效且经济的新一代 Embedding 模型，适用于知识检索、RAG 应用等场景",
    "meta/llama-3.2-3b-instruct": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。",
    "qwen/qwen3-8b:free": "Qwen3-8B 是 Qwen3 系列中一个密集的 82 亿参数因果语言模型，专为推理密集型任务和高效对话而设计。它支持在用于数学、编码和逻辑推理的“思考”模式与用于一般对话的“非思考”模式之间无缝切换。该模型经过微调，可用于指令遵循、代理集成、创意写作以及跨 100 多种语言和方言的多语言使用。它原生支持 32K 令牌上下文窗口，并可通过 YaRN 扩展到 131K 令牌。",
    "jamba-large": "我们最强大、最先进的模型，专为处理企业级复杂任务而设计，具备卓越的性能。",
    "deepseek-v3": "DeepSeek-V3 是一个强大的专家混合（MoE）语言模型，拥有总计 6710 亿参数，每个 token 激活 370 亿参数。",
    "gpt-4o-mini-realtime-preview": "GPT-4o-mini 实时版本，支持音频和文本实时输入输出",
    "google/gemma-2-27b": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。",
    "yi-spark": "小而精悍，轻量极速模型。提供强化数学运算和代码编写能力。",
    "hunyuan-translation": "支持中文和英语、日语、法语、葡萄牙语、西班牙语、土耳其语、俄语、阿拉伯语、韩语、意大利语、德语、越南语、马来语、印尼语15种语言互译，基于多场景翻译评测集自动化评估COMET评分，在十余种常用语种中外互译能力上整体优于市场同规模模型。",
    "Vendor-A/Qwen/Qwen2.5-72B-Instruct": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "grok-2-vision-1212": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
    "qwen/qwen-2-vl-72b-instruct": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
    "gpt-4-0125-preview": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
    "google/gemini-2.0-flash-exp:free": "Gemini 2.0 Flash Experimental 是 Google 最新的实验性多模态AI模型，与历史版本相比有一定的质量提升，特别是对于世界知识、代码和长上下文。",
    "cohere-command-r": "Command R是一个可扩展的生成模型，旨在针对RAG和工具使用，使企业能够实现生产级AI。",
    "360gpt2-o1": "360gpt2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。",
    "qwen-math-plus-latest": "通义千问数学模型是专门用于数学解题的语言模型。",
    "ernie-x1-turbo-32k": "与ERNIE-X1-32K相比，模型效果和性能更好。",
    "hunyuan-standard-256K": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-256K 在长度和效果上进一步突破，极大的扩展了可输入长度。",
    "4.0Ultra": "Spark Ultra 是星火大模型系列中最为强大的版本，在升级联网搜索链路同时，提升对文本内容的理解和总结能力。它是用于提升办公生产力和准确响应需求的全方位解决方案，是引领行业的智能产品。",
    "Pro/THUDM/glm-4-9b-chat": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
    "accounts/fireworks/models/mixtral-8x7b-instruct": "Mixtral MoE 8x7B Instruct 是 Mixtral MoE 8x7B 的指令微调版本，已启用聊天完成功能 API。",
    "qwen-vl-v1": "以 Qwen-7B 语言模型初始化，添加图像模型，图像输入分辨率为448的预训练模型。",
    "dall-e-2": "第二代 DALL·E 模型，支持更真实、准确的图像生成，分辨率是第一代的4倍",
    "yi-medium-200k": "200K 超长上下文窗口，提供长文本深度理解和生成能力。",
    "meta-llama-3.1-70b-instruct": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
    "Qwen/Qwen2-VL-72B-Instruct": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
    "sonar-reasoning-pro": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。",
    "qwen3-8b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "sonar-pro": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。",
    "deepseek-r1-distill-qianfan-llama-70b": "2025年2月14日首次发布，由千帆大模型研发团队以 Llama3_70B为base模型（Built with Meta Llama）蒸馏所得，蒸馏数据中也同步添加了千帆的语料。",
    "yi-large-turbo": "超高性价比、卓越性能。根据性能和推理速度、成本，进行平衡性高精度调优。",
    "Llama-3.2-90B-Vision-Instruct\t": "适用于视觉理解代理应用的高级图像推理能力。",
    "meta-llama/Llama-3-8b-chat-hf": "Llama 3 8B Instruct Reference 提供多语言支持，涵盖丰富的领域知识。",
    "solar-pro": "Solar Pro 是 Upstage 推出的一款高智能LLM，专注于单GPU的指令跟随能力，IFEval得分80以上。目前支持英语，正式版本计划于2024年11月推出，将扩展语言支持和上下文长度。",
    "qwq_32b": "Qwen 系列中等规模的推理模型。与传统的指令调优模型相比，具备思考和推理能力的 QwQ 在下游任务中，尤其是在解决难题时，能够显著提升性能。",
    "deepseek-coder-v2:236b": "DeepSeek Coder V2 是开源的混合专家代码模型，在代码任务方面表现优异，与 GPT4-Turbo 相媲美。",
    "llava-v1.5-7b-4096-preview": "LLaVA 1.5 7B 提供视觉处理能力融合，通过视觉信息输入生成复杂输出。",
    "openai/gpt-4.1-nano": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。",
    "meta-llama/Llama-Vision-Free": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "openai/o1-mini": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。",
    "codestral": "Codestral 是 Mistral AI 的首款代码模型，为代码生成任务提供优异支持。",
    "accounts/fireworks/models/llama-v3p1-70b-instruct": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 三种参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话应用优化，并在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。",
    "thudm/glm-z1-9b:free": "GLM-Z1-9B-0414 是由 THUDM 开发的 GLM-4 系列中的 9B 参数语言模型。它采用了最初应用于更大 GLM-Z1 模型的技术，包括扩展强化学习、成对排名对齐以及对数学、代码和逻辑等推理密集型任务的训练。尽管其规模较小，但它在通用推理任务上表现出强大的性能，并在其权重级别中优于许多开源模型。",
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": "Llama 3.1 8B 模型采用FP8量化，支持高达131,072个上下文标记，是开源模型中的佼佼者，适合复杂任务，表现优异于许多行业基准。",
    "glm-4-airx": "GLM-4-AirX 提供 GLM-4-Air 的高效版本，推理速度可达其2.6倍。",
    "qwen2.5:1.5b": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "llava": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。",
    "qwq-plus-latest": "基于 Qwen2.5 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平。",
    "qwen-turbo-latest": "通义千问超大规模语言模型，支持中文、英文等不同语言输入。",
    "SenseChat-5-Cantonese": "专门为适应香港地区的对话习惯、俚语及本地知识而设计，在粤语的对话理解上超越了GPT-4，在知识、推理、数学及代码编写等多个领域均能与GPT-4 Turbo相媲美。",
    "step-1v-32k": "支持视觉输入，增强多模态交互体验。",
    "qwen2.5-vl-72b-instruct": "指令跟随、数学、解题、代码整体提升，万物识别能力提升，支持多样格式直接精准定位视觉元素，支持对长视频文件（最长10分钟）进行理解和秒级别的事件时刻定位，能理解时间先后和快慢，基于解析和定位能力支持操控OS或Mobile的Agent，关键信息抽取能力和Json格式输出能力强，此版本为72B版本，本系列能力最强的版本。",
    "deepseek-v2:236b": "DeepSeek V2 236B 是 DeepSeek 的设计代码模型，提供强大的代码生成能力。",
    "command-light": "一个更小、更快的 Command 版本，几乎同样强大，但速度更快。",
    "Qwen2.5-7B-Instruct": "通义千问2.5对外开源的7B规模的模型。",
    "ERNIE-3.5-8K": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。",
    "gemini-2.5-pro-preview-03-25": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。",
    "hunyuan-code": "混元最新代码生成模型，经过 200B 高质量代码数据增训基座模型，迭代半年高质量 SFT 数据训练，上下文长窗口长度增大到 8K，五大语言代码生成自动评测指标上位居前列；五大语言10项考量各方面综合代码任务人工高质量评测上，性能处于第一梯队",
    "command-r-plus": "Command R+ 是一款高性能的大型语言模型，专为真实企业场景和复杂应用而设计。",
    "qwen2:0.5b": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "grok-2-1212": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
    "open-mixtral-8x22b": "Mixtral 8x22B是一个更大的专家模型，专注于复杂任务，提供出色的推理能力和更高的吞吐量。",
    "Qwen2-72B-Instruct": "Qwen2 是 Qwen 团队推出的新一代大型语言模型系列。它基于 Transformer 架构，并采用 SwiGLU 激活函数、注意力 QKV 偏置(attention QKV bias)、群组查询注意力(group query attention)、滑动窗口注意力(mixture of sliding window attention)与全注意力的混合等技术。此外，Qwen 团队还改进了适应多种自然语言和代码的分词器。",
    "gpt-3.5-turbo-instruct": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
    "Qwen2.5-72B-Instruct": "面向中文和英文的 LLM，针对语言、编程、数学、推理等领域。",
    "gemini-2.0-flash-preview-image-generation": "Gemini 2.0 Flash 预览模型，支持图像生成",
    "Baichuan3-Turbo": "针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。",
    "taichu_vl": "融合了图像理解、知识迁移、逻辑归因等能力，在图文问答领域表现突出",
    "openrouter/auto": "根据上下文长度、主题和复杂性，你的请求将发送到 Llama 3 70B Instruct、Claude 3.5 Sonnet（自我调节）或 GPT-4o。",
    "thudm/glm-4-9b-chat": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
    "moonshot-v1-8k": "Moonshot V1 8K 专为生成短文本任务设计，具有高效的处理性能，能够处理8,192个tokens，非常适合简短对话、速记和快速内容生成。",
    "gpt-4": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
    "ernie-tiny-8k": "ERNIE Tiny是百度自研的超高性能大语言模型，部署与精调成本在文心系列模型中最低。",
    "Qwen/Qwen2.5-7B-Instruct-Turbo": "Qwen2.5 是全新的大型语言模型系列，旨在优化指令式任务的处理。",
    "deepseek-ai/deepseek-r1": "DeepSeek-R1 系列通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆，超越 OpenAI-o1-mini 水平。",
    "solar-mini-ja": "Solar Mini (Ja) 扩展了 Solar Mini 的能力，专注于日语，同时在英语和韩语的使用中保持高效和卓越性能。",
    "codestral-latest": "Codestral 是我们最先进的编码语言模型，第二个版本于2025年1月发布，专门从事低延迟、高频任务如中间填充（RST）、代码纠正和测试生成。",
    "meta-llama/llama-3.1-8b-instruct": "Meta最新一代的Llama 3.1模型系列，8B（80亿参数）的指令微调版本特别快速高效。在业界评估中，表现出强劲的性能，超越了很多领先的闭源模型。(仅针对企业实名认证通过主体开放）",
    "Meta-Llama-3.2-1B-Instruct": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。",
    "minicpm-v": "MiniCPM-V 是 OpenBMB 推出的新一代多模态大模型，具备卓越的 OCR 识别和多模态理解能力，支持广泛的应用场景。",
    "google/gemma-2b-it": "Gemma Instruct (2B) 提供基本的指令处理能力，适合轻量级应用。",
    "gpt-3.5-turbo-1106": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
    "glm-4-flash": "GLM-4-Flash 是处理简单任务的理想选择，速度最快且免费。",
    "anthropic/claude-3.5-haiku": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",
    "qwen/qwen-2-7b-instruct:free": "Qwen2 是全新的大型语言模型系列，具有更强的理解和生成能力。",
    "accounts/fireworks/models/llama-v3-8b-instruct": "Meta 开发并发布了 Meta Llama 3 系列大语言模型（LLM），这是一个包含 8B 和 70B 参数规模的预训练和指令微调生成文本模型的集合。Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。",
    "accounts/fireworks/models/llama-v3-8b-instruct-hf": "Meta Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。Llama 3 8B Instruct（HF 版本）是 Llama 3 8B Instruct 的原始 FP16 版本，其结果应与官方 Hugging Face 实现一致。",
    "gpt-4o": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "llama-3.2-vision-instruct": "Llama 3.2-Vision 指令微调模型针对视觉识别、图像推理、图像描述和回答与图像相关的常规问题进行了优化。",
    "sonar-deep-research": "Deep Research 进行全面的专家级研究，并将其综合成可访问、可作的报告。",
    "claude-3-opus-20240229": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。",
    "amazon.titan-text-premier-v1:0": "Titan Text Premier 是 Titan Text 系列中一款强大的先进模型，旨在为广泛的企业应用提供卓越的性能。凭借其尖端能力，它提供了更高的准确性和卓越的结果，是寻求一流文本处理解决方案的组织的绝佳选择。",
    "deepseek-r1-70b-fast-online": "DeepSeek R1 70B 快速版，支持实时联网搜索，在保持模型性能的同时提供更快的响应速度。",
    "deepseek-ai/DeepSeek-V2.5": "DeepSeek-V2.5 是 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的升级版本，集成了两个先前版本的通用和编码能力。该模型在多个方面进行了优化，包括写作和指令跟随能力，更好地与人类偏好保持一致。DeepSeek-V2.5 在各种评估基准上都取得了显著的提升，如 AlpacaEval 2.0、ArenaHard、AlignBench 和 MT-Bench 等。",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。",
    "llava:34b": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。",
    "Skylark2-pro-character-4k": "云雀（Skylark）第二代模型，Skylark2-pro-character模型具有优秀的角色扮演和聊天能力，擅长根据用户prompt要求扮演不同角色与用户展开聊天，角色风格突出，对话内容自然流畅，适用于构建聊天机器人、虚拟助手和在线客服等场景，有较高的响应速度。",
    "deepseek_r1_distill_llama_70b": "DeepSeek-R1-Distill-Llama-70B 是基于 Llama-3.3-70B-Instruct 经过蒸馏训练得到的模型。该模型是 DeepSeek-R1 系列的一部分，通过使用 DeepSeek-R1 生成的样本进行微调，在数学、编程和推理等多个领域展现出优秀的性能。",
    "Qwen2.5-32B-Instruct": "通义千问2.5对外开源的32B规模的模型。",
    "glm-4-0520": "GLM-4-0520 是最新模型版本，专为高度复杂和多样化任务设计，表现卓越。",
    "MiniMax-Text-01": "在 MiniMax-01系列模型中，我们做了大胆创新：首次大规模实现线性注意力机制，传统 Transformer架构不再是唯一的选择。这个模型的参数量高达4560亿，其中单次激活459亿。模型综合性能比肩海外顶尖模型，同时能够高效处理全球最长400万token的上下文，是GPT-4o的32倍，Claude-3.5-Sonnet的20倍。",
    "gemini-1.5-pro-exp-0827": "Gemini 1.5 Pro 0827 结合最新优化技术，带来更高效的多模态数据处理能力。",
    "mistralai/Mixtral-8x22B-Instruct-v0.1": "Mixtral-8x22B Instruct (141B) 是一款超级大语言模型，支持极高的处理需求。",
    "DeepSeek-R1-Distill-Qwen-1.5B": "DeepSeek-R1-Distill-Qwen-1.5B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。",
    "THUDM/GLM-Z1-9B-0414": "GLM-Z1-9B-0414 是 GLM 系列的小型模型，仅有 90 亿参数，但保持了开源传统的同时展现出惊人的能力。尽管规模较小，该模型在数学推理和通用任务上仍表现出色，其总体性能在同等规模的开源模型中已处于领先水平。",
    "o1-mini": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。",
    "ernie-4.5-turbo-128k": "文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。模型能力全面提升，更好满足多轮长历史对话处理、长文档理解问答任务。",
    "qwen2.5-vl-instruct": "Qwen2.5-VL 是 Qwen 模型家族中视觉语言模型的最新版本。",
    "moonshot-v1-128k-vision-preview": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。",
    "anthropic.claude-3-opus-20240229-v1:0": "Claude 3 Opus 是 Anthropic 最强大的 AI 模型，具有在高度复杂任务上的最先进性能。它可以处理开放式提示和未见过的场景，具有出色的流畅性和类人的理解能力。Claude 3 Opus 展示了生成 AI 可能性的前沿。Claude 3 Opus 可以处理图像并返回文本输出，具有 200K 的上下文窗口。",
    "llama3-8b-8192": "Meta Llama 3 8B 带来优质的推理效能，适合多场景应用需求。",
    "command": "一个遵循指令的对话模型，在语言任务中表现出高质量、更可靠，并且相比我们的基础生成模型具有更长的上下文长度。",
    "DeepSeek-R1-Distill-Qwen-7B": "DeepSeek-R1-Distill-Qwen-7B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。",
    "Qwen/Qwen2.5-Coder-32B-Instruct": "Qwen2.5 Coder 32B Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
    "meta-llama/llama-3.2-90b-vision-instruct": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "deepseek/deepseek-r1:free": "DeepSeek-R1 在仅有极少标注数据的情况下，极大提升了模型推理能力。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。",
    "accounts/fireworks/models/mythomax-l2-13b": "MythoMix 的改进版，可能是其更为完善的变体，是 MythoLogic-L2 和 Huginn 的合并，采用了高度实验性的张量类型合并技术。由于其独特的性质，该模型在讲故事和角色扮演方面表现出色。",
    "deepseek/deepseek-v3/community": "DeepSeek-V3在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。",
    "gemini-2.0-flash-lite": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。",
    "SenseNova-V6-Pro": "实现图片、文本、视频能力的原生统一，突破传统多模态分立局限，在OpenCompass和SuperCLUE评测中斩获双冠军。",
    "ernie-x1-32k": "具备更强的理解、规划、反思、进化能力。作为能力更全面的深度思考模型，文心X1兼备准确、创意和文采，在中文知识问答、文学创作、文稿写作、日常对话、逻辑推理、复杂计算及工具调用等方面表现尤为出色。",
    "gemini-2.0-flash-lite-001": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。",
    "charglm-3": "CharGLM-3 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。",
    "openai/o3-mini-high": "o3-mini 高推理等级版，在与 o1-mini 相同的成本和延迟目标下提供高智能。",
    "gpt-4.1-nano": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。",
    "Doubao-lite-128k": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 128k 上下文窗口的推理和精调。",
    "qwen/qwen3-30b-a3b:free": "Qwen3 是 Qwen 大型语言模型系列的最新一代，具有密集和专家混合 (MoE) 架构，在推理、多语言支持和高级代理任务方面表现出色。其在复杂推理的思考模式和高效对话的非思考模式之间无缝切换的独特能力确保了多功能、高质量的性能。\\n\\nQwen3 显著优于 QwQ 和 Qwen2.5 等先前模型，提供卓越的数学、编码、常识推理、创意写作和交互式对话能力。Qwen3-30B-A3B 变体包含 305 亿个参数（33 亿个激活参数）、48 层、128 个专家（每个任务激活 8 个），并支持高达 131K 令牌上下文（使用 YaRN），为开源模型树立了新标准。",
    "Pro/Qwen/Qwen2.5-7B-Instruct": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "accounts/fireworks/models/llama-v3p2-3b-instruct": "Llama 3.2 3B Instruct 是 Meta 推出的轻量级多语言模型。该模型专为高效运行而设计，相较于更大型的模型，具有显著的延迟和成本优势。其典型应用场景包括查询和提示重写，以及写作辅助。",
    "Phi-3-small-128k-instruct": "相同的Phi-3-small模型，但具有更大的上下文大小，适用于RAG或少量提示。",
    "meta/llama-3.1-405b-instruct": "高级 LLM，支持合成数据生成、知识蒸馏和推理，适用于聊天机器人、编程和特定领域任务。",
    "deepseek-ai/deepseek-vl2": "DeepSeek-VL2 是一个基于 DeepSeekMoE-27B 开发的混合专家（MoE）视觉语言模型，采用稀疏激活的 MoE 架构，在仅激活 4.5B 参数的情况下实现了卓越性能。该模型在视觉问答、光学字符识别、文档/表格/图表理解和视觉定位等多个任务中表现优异。",
    "gemini-1.5-pro-001": "Gemini 1.5 Pro 001 是可扩展的多模态AI解决方案，支持广泛的复杂任务。",
    "qwen/qwen3-32b:free": "Qwen3-32B 是 Qwen3 系列中一个密集的 328 亿参数因果语言模型，针对复杂推理和高效对话进行了优化。它支持在用于数学、编码和逻辑推理等任务的“思考”模式与用于更快、通用对话的“非思考”模式之间无缝切换。该模型在指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务中表现出强大的性能。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。",
    "glm-4v-flash": "GLM-4V-Flash 专注于高效的单一图像理解，适用于快速图像解析的场景，例如实时图像分析或批量图像处理。",
    "Phi-3-mini-4k-instruct": "Phi-3家族中最小的成员，针对质量和低延迟进行了优化。",
    "THUDM/GLM-4-9B-0414": "GLM-4-9B-0414 是 GLM 系列的小型模型，拥有 90 亿参数。该模型继承了 GLM-4-32B 系列的技术特点，但提供了更轻量级的部署选择。尽管规模较小，GLM-4-9B-0414 仍在代码生成、网页设计、SVG 图形生成和基于搜索的写作等任务上展现出色能力。",
    "yi-large-preview": "初期版本，推荐使用 yi-large（新版本）。",
    "deepseek-v3-0324": "DeepSeek-V3-0324 为671B 参数 MoE 模型，在编程与技术能力、上下文理解与长文本处理等方面优势突出。",
    "Skylark2-pro-turbo-8k": "云雀（Skylark）第二代模型，Skylark2-pro-turbo-8k推理更快，成本更低，上下文窗口长度为8k。",
    "moonshot-v1-8k-vision-preview": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。",
    "qwen-plus": "通义千问超大规模语言模型增强版，支持中文、英文等不同语言输入。",
    "gemini-1.5-flash-8b-latest": "Gemini 1.5 Flash 8B 是一款高效的多模态模型，支持广泛应用的扩展。",
    "gpt-4o-realtime-preview-2024-10-01": "GPT-4o 实时版本，支持音频和文本实时输入输出",
    "nousresearch/hermes-2-pro-llama-3-8b": "Hermes 2 Pro Llama 3 8B 是 Nous Hermes 2的升级版本，包含最新的内部开发的数据集。",
    "step-1o-turbo-vision": "该模型拥有强大的图像理解能力，在数理、代码领域强于1o。模型比1o更小，输出速度更快。",
    "accounts/fireworks/models/qwen2p5-coder-32b-instruct": "Qwen2.5-Coder 是最新一代专为代码设计的 Qwen 大型语言模型（前称为 CodeQwen）。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。",
    "anthropic/claude-3-haiku": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。",
    "gemini-1.0-pro-latest": "Gemini 1.0 Pro 是Google的高性能AI模型，专为广泛任务扩展而设计。",
    "meta-llama/Meta-Llama-3-70B-Instruct-Lite": "Llama 3 70B Instruct Lite 适合需要高效能和低延迟的环境。",
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": "Llama 3.1 70B 模型经过精细调整，适用于高负载应用，量化至FP8提供更高效的计算能力和准确性，确保在复杂场景中的卓越表现。",
    "THUDM/chatglm3-6b": "ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用",
    "moonshot-v1-128k": "Moonshot V1 128K 是一款拥有超长上下文处理能力的模型，适用于生成超长文本，满足复杂的生成任务需求，能够处理多达128,000个tokens的内容，非常适合科研、学术和大型文档生成等应用场景。",
    "accounts/fireworks/models/qwen-qwq-32b-preview": "Qwen QwQ 模型专注于推动 AI 推理，并展示了开放模型在推理能力上与闭源前沿模型匹敌的力量。QwQ-32B-Preview 是一个实验性发布版本，在 GPQA、AIME、MATH-500 和 LiveCodeBench 基准测试中，在分析和推理能力上可与 o1 相媲美，并超越 GPT-4o 和 Claude 3.5 Sonnet。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。",
    "ernie-lite-8k": "ERNIE Lite是百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，适合低算力AI加速卡推理使用。",
    "glm-zero-preview": "GLM-Zero-Preview具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。",
    "Meta-Llama-3.3-70B-Instruct": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月",
    "meta-llama/Meta-Llama-3.1-70B": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。",
    "360/deepseek-r1": "【360部署版】DeepSeek-R1在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。",
    "anthropic.claude-3-5-sonnet-20241022-v2:0": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。",
    "deepseek/deepseek-r1-distill-qwen-32b": "DeepSeek R1 Distill Qwen 32B 是一种基于 Qwen 2.5 32B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces Rating: 1691\\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。",
    "internlm2.5-latest": "我们仍在维护的老版本模型，经过多轮迭代有着极其优异且稳定的性能，包含 7B、20B 多种模型参数量可选，支持 1M 的上下文长度以及更强的指令跟随和工具调用能力。默认指向我们最新发布的 InternLM2.5 系列模型，当前指向 internlm2.5-20b-chat。",
    "emohaa": "Emohaa 是心理模型，具备专业咨询能力，帮助用户理解情感问题。",
    "qwen3-235b-a22b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "qwen2.5-vl-32b-instruct": "Qwen2.5VL系列模型，在math和学科问题解答达到了接近Qwen2.5VL-72B的水平，回复风格面向人类偏好进行大幅调整，尤其是数学、逻辑推理、知识问答等客观类query，模型回复详实程度和格式清晰度明显改善。此版本为32B版本。",
    "ERNIE-Lite-Pro-128K": "百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，效果比ERNIE Lite更优，适合低算力AI加速卡推理使用。",
    "mistral-nemo-instruct": "Mistral-Nemo-Instruct-2407 大型语言模型（LLM）是 Mistral-Nemo-Base-2407 的指令微调版本。",
    "gpt-35-turbo": "GPT 3.5 Turbo，OpenAI提供的高效模型，适用于聊天和文本生成任务，支持并行函数调用。",
    "llama-2-7b-chat": "Llama2 是由 Meta 开发并开源的大型语言模型（LLM）系列，这是一组从 70 亿到 700 亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，LLama2 是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2 较 Llama 系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。",
    "Qwen/Qwen2-7B-Instruct": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
    "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) 是高精度的指令模型，适用于复杂计算。",
    "Phi-3.5-mini-instruct": "Phi-3-mini模型的更新版。",
    "qwen/qwen-2.5-72b-instruct": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升。",
    "Qwen/QwQ-32B": "QwQ 是 Qwen 系列的推理模型。与传统的指令调优模型相比，QwQ 具备思考和推理能力，能够在下游任务中实现显著增强的性能，尤其是在解决困难问题方面。QwQ-32B 是中型推理模型，能够在与最先进的推理模型（如 DeepSeek-R1、o1-mini）的对比中取得有竞争力的性能。该模型采用 RoPE、SwiGLU、RMSNorm 和 Attention QKV bias 等技术，具有 64 层网络结构和 40 个 Q 注意力头（GQA 架构中 KV 为 8 个）。",
    "deepseek-coder-v2": "DeepSeek Coder V2 是开源的混合专家代码模型，在代码任务方面表现优异，与 GPT4-Turbo 相媲美。",
    "llama-3.1-instruct": "Llama 3.1 指令微调模型针对对话场景进行了优化，在常见的行业基准测试中，超越了许多现有的开源聊天模型。",
    "gemini-1.5-flash-latest": "Gemini 1.5 Flash 是Google最新的多模态AI模型，具备快速处理能力，支持文本、图像和视频输入，适用于多种任务的高效扩展。",
    "hunyuan-pro": "万亿级参数规模 MOE-32K 长文模型。在各种 benchmark 上达到绝对领先的水平，复杂指令和推理，具备复杂数学能力，支持 functioncall，在多语言翻译、金融法律医疗等领域应用重点优化。",
    "microsoft/wizardlm-2-8x22b": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。",
    "grok-3-beta": "旗舰级模型，擅长数据提取、编程和文本摘要等企业级应用，拥有金融、医疗、法律和科学等领域的深厚知识。",
    "qwen2.5-coder-7b-instruct": "通义千问代码模型开源版。",
    "glm-4-flash-250414": "GLM-4-Flash 是处理简单任务的理想选择，速度最快且免费。",
    "doubao-1.5-vision-lite": "Doubao-1.5-vision-lite 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。支持 128k 上下文窗口，输出长度支持最大 16k tokens。",
    "Doubao-lite-32k": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 32k 上下文窗口的推理和精调。",
    "command-a-03-2025": "Command A 是我们迄今为止性能最强的模型，在工具使用、代理、检索增强生成（RAG）和多语言应用场景方面表现出色。Command A 具有 256K 的上下文长度，仅需两块 GPU 即可运行，并且相比于 Command R+ 08-2024，吞吐量提高了 150%。",
    "codellama": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。",
    "qwen/qwen-2-7b-instruct": "Qwen2是全新的Qwen大型语言模型系列。Qwen2 7B是一个基于transformer的模型，在语言理解、多语言能力、编程、数学和推理方面表现出色。",
    "llama-3.3-70b-instruct": "Meta 发布的 LLaMA 3.3 多语言大规模语言模型（LLMs）是一个经过预训练和指令微调的生成模型，提供 70B 规模（文本输入/文本输出）。该模型使用超过 15T 的数据进行训练，支持英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语和泰语，知识更新截止于 2023 年 12 月。",
    "gemini-1.5-pro-latest": "Gemini 1.5 Pro 支持高达200万个tokens，是中型多模态模型的理想选择，适用于复杂任务的多方面支持。",
    "gpt-4-turbo": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
    "gpt-4-0613": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
    "tts-1-hd": "最新的文本转语音模型，针对质量进行优化",
    "llama-3.2-11b-vision-preview": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。",
    "google/gemma-2-9b-it": "Gemma 2 9B 由Google开发，提供高效的指令响应和综合能力。",
    "gpt-4o-mini-tts": "GPT-4o mini TTS 是一个基于 GPT-4o mini 构建的文本转语音模型，这是一种快速且强大的语言模型。使用它可以将文本转换为自然听起来的语音文本。最大输入标记数为 2000。",
    "mixtral-8x7b-32768": "Mixtral 8x7B 提供高容错的并行计算能力，适合复杂任务。",
    "ernie-4.5-8k-preview": "文心大模型4.5是百度自主研发的新一代原生多模态基础大模型，通过多个模态联合建模实现协同优化，多模态理解能力优秀；具备更精进的语言能力，理解、生成、逻辑、记忆能力全面提升，去幻觉、逻辑推理、代码能力显著提升。",
    "pixtral-12b-2409": "Pixtral 模型在图表和图理解、文档问答、多模态推理和指令遵循等任务上表现出强大的能力，能够以自然分辨率和宽高比摄入图像，还能够在长达 128K 令牌的长上下文窗口中处理任意数量的图像。",
    "anthropic.claude-3-5-sonnet-20240620-v1:0": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。",
    "gemini-1.0-pro-001": "Gemini 1.0 Pro 001 (Tuning) 提供稳定并可调优的性能，是复杂任务解决方案的理想选择。",
    "dall-e-3": "最新的 DALL·E 模型，于2023年11月发布。支持更真实、准确的图像生成，具有更强的细节表现力",
    "meta-llama/llama-3-70b-instruct": "Llama 3 70B Instruct 优化用于高质量对话场景，在各类人类评估中表现优异。",
    "mistralai/mistral-nemo": "Mistral Nemo 是多语言支持和高性能编程的7.3B参数模型。",
    "yi-medium": "中型尺寸模型升级微调，能力均衡，性价比高。深度优化指令遵循能力。",
    "Qwen/Qwen2.5-VL-72B-Instruct": "Qwen2.5-VL 是 Qwen2.5 系列中的视觉语言模型。该模型在多方面有显著提升：具备更强的视觉理解能力，能够识别常见物体、分析文本、图表和布局；作为视觉代理能够推理并动态指导工具使用；支持理解超过 1 小时的长视频并捕捉关键事件；能够通过生成边界框或点准确定位图像中的物体；支持生成结构化输出，尤其适用于发票、表格等扫描数据。",
    "01-ai/yi-1.5-34b-chat": "零一万物，最新开源微调模型，340亿参数，微调支持多种对话场景，高质量训练数据，对齐人类偏好。",
    "qwen3-0.6b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "abab6.5s-chat": "适用于广泛的自然语言处理任务，包括文本生成、对话系统等。",
    "deepseek_r1_distill_qwen_14b": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。",
    "doubao-1.5-thinking-pro": "Doubao-1.5全新深度思考模型，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。",
    "meta/llama-3.2-90b-vision-instruct": "尖端的视觉-语言模型，擅长从图像中进行高质量推理。",
    "qwen/qwen3-30b-a3b": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。",
    "qvq-72b-preview": "QVQ-72B-Preview 是由 Qwen 团队开发的实验性研究模型，专注于提升视觉推理能力。",
    "codegemma:2b": "CodeGemma 专用于不同编程任务的轻量级语言模型，支持快速迭代和集成。",
    "google/gemini-2.5-flash-preview": "Gemini 2.5 Flash 是 Google 最先进的主力模型，专为高级推理、编码、数学和科学任务而设计。它包含内置的“思考”能力，使其能够提供具有更高准确性和细致上下文处理的响应。\\n\\n注意：此模型有两个变体：思考和非思考。输出定价根据思考能力是否激活而有显著差异。如果您选择标准变体（不带“:thinking”后缀），模型将明确避免生成思考令牌。\\n\\n要利用思考能力并接收思考令牌，您必须选择“:thinking”变体，这将产生更高的思考输出定价。\\n\\n此外，Gemini 2.5 Flash 可通过“推理最大令牌数”参数进行配置，如文档中所述 (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)。",
    "amazon.titan-text-lite-v1": "亚马逊 Titan Text Lite 是一款轻量级高效模型，非常适合对英语任务进行微调，包括总结和文案编写等，客户希望有一个更小、更经济的模型，同时也非常可定制。",
    "gemini-2.0-flash-exp-image-generation": "Gemini 2.0 Flash 实验模型，支持图像生成",
    "mistral-medium-latest": "Mistral Medium 3 以 8 倍的成本提供最先进的性能，并从根本上简化了企业部署。",
    "qwen3": "Qwen3 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。",
    "meta-llama/Llama-2-70b-hf": "LLaMA-2 提供优秀的语言处理能力和出色的交互体验。",
    "codegemma": "CodeGemma 专用于不同编程任务的轻量级语言模型，支持快速迭代和集成。",
    "SenseChat-32K": "基础版本模型 (V4)，32K上下文长度，灵活应用于各类场景",
    "grok-3-mini-beta": "轻量级模型，回话前会先思考。运行快速、智能，适用于不需要深层领域知识的逻辑任务，并能获取原始的思维轨迹。",
    "accounts/fireworks/models/mistral-small-24b-instruct-2501": "24B 参数模型，具备与更大型模型相当的最先进能力。",
    "deepseek-reasoner": "DeepSeek 推出的推理模型。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。",
    "SenseChat-5": "最新版本模型 (V5.5)，128K上下文长度，在数学推理、英文对话、指令跟随以及长文本理解等领域能力显著提升，比肩GPT-4o。",
    "google/gemini-2.5-flash-preview:thinking": "Gemini 2.5 Flash 是 Google 最先进的主力模型，专为高级推理、编码、数学和科学任务而设计。它包含内置的“思考”能力，使其能够提供具有更高准确性和细致上下文处理的响应。\\n\\n注意：此模型有两个变体：思考和非思考。输出定价根据思考能力是否激活而有显著差异。如果您选择标准变体（不带“:thinking”后缀），模型将明确避免生成思考令牌。\\n\\n要利用思考能力并接收思考令牌，您必须选择“:thinking”变体，这将产生更高的思考输出定价。\\n\\n此外，Gemini 2.5 Flash 可通过“推理最大令牌数”参数进行配置，如文档中所述 (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)。",
    "accounts/yi-01-ai/models/yi-large": "Yi-Large 是顶尖的大型语言模型之一，在 LMSYS 基准测试排行榜上，其表现仅次于 GPT-4、Gemini 1.5 Pro 和 Claude 3 Opus。它在多语言能力方面表现卓越，特别是在西班牙语、中文、日语、德语和法语方面。Yi-Large 还具有用户友好性，采用与 OpenAI 相同的 API 定义，便于集成。",
    "jamba-mini": "在同级别中最高效的模型，兼顾速度与质量，具备更小的体积。",
    "step-1-128k": "平衡性能与成本，适合一般场景。",
    "gemini-2.5-flash-preview-04-17": "Gemini 2.5 Flash Preview 是 Google 性价比最高的模型，提供全面的功能。",
    "gpt-4-turbo-2024-04-09": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
    "cognitivecomputations/dolphin-mixtral-8x22b": "Dolphin Mixtral 8x22B 是一款为指令遵循、对话和编程设计的模型。",
    "grok-beta": "拥有与 Grok 2 相当的性能，但具有更高的效率、速度和功能。",
    "qwen2.5-math-7b-instruct": "Qwen-Math 模型具有强大的数学解题能力。",
    "mistralai/Mixtral-8x7B-Instruct-v0.1": "Mixtral-8x7B Instruct (46.7B) 提供高容量的计算框架，适合大规模数据处理。",
    "qwen-plus-latest": "通义千问超大规模语言模型增强版，支持中文、英文等不同语言输入。",
    "Skylark2-pro-32k": "云雀（Skylark）第二代模型，Skylark2-pro版本有较高的模型精度，适用于较为复杂的文本生成场景，如专业领域文案生成、小说创作、高质量翻译等，上下文窗口长度为32k。",
    "accounts/fireworks/models/llama-v3p3-70b-instruct": "Llama 3.3 70B Instruct 是 Llama 3.1 70B 的 12 月更新版本。该模型在 Llama 3.1 70B（于 2024 年 7 月发布）的基础上进行了改进，增强了工具调用、多语言文本支持、数学和编程能力。该模型在推理、数学和指令遵循方面达到了行业领先水平，并且能够提供与 3.1 405B 相似的性能，同时在速度和成本上具有显著优势。",
    "DeepSeek-R1-Distill-Qwen-32B": "DeepSeek-R1-Distill-Qwen-32B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。",
    "llama3.1:405b": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。",
    "yi-1.5-34b-chat": "Yi-1.5 是 Yi 的升级版本。 它使用 500B Tokens 的高质量语料库在 Yi 上持续进行预训练，并在 3M 个多样化的微调样本上进行微调。",
    "llama-3.1-70b-versatile": "Llama 3.1 70B 提供更强大的AI推理能力，适合复杂应用，支持超多的计算处理并保证高效和准确率。",
    "google/gemini-pro-1.5": "Gemini 1.5 Pro 结合最新优化技术，带来更高效的多模态数据处理能力。",
    "DeepSeek-R1-Distill-Qwen-14B": "DeepSeek-R1-Distill-Qwen-14B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。",
    "SenseChat-Character-Pro": "拟人对话高级版模型，32K上下文长度，能力全面提升，支持中/英文对话",
    "gpt-4-turbo-preview": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
    "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": "Meta 推出的指令微调图像推理模型，拥有 110 亿参数。该模型针对视觉识别、图像推理、图片字幕生成以及图片相关的常规问答进行了优化。它能够理解视觉数据，如图表和图形，并通过生成文本描述图像细节，弥合视觉与语言之间的鸿沟。",
    "codellama:13b": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。",
    "meta-llama/llama-3.1-70b-instruct": "Meta最新一代的Llama 3.1模型系列，70B（700亿参数）的指令微调版本针对高质量对话场景进行了优化。在业界评估中，与领先的闭源模型相比，它展现出了强劲的性能。(仅针对企业实名认证通过主体开放）",
    "mistral-large": "Mixtral Large 是 Mistral 的旗舰模型，结合代码生成、数学和推理的能力，支持 128k 上下文窗口。",
    "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": "DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力。",
    "deepseek-v2": "DeepSeek V2 是高效的 Mixture-of-Experts 语言模型，适用于经济高效的处理需求。",
    "ernie-novel-8k": "百度自研通用大语言模型，在小说续写能力上有明显优势，也可用在短剧、电影等场景。",
    "Qwen/Qwen2-72B-Instruct": "Qwen 2 Instruct (72B) 为企业级应用提供精准的指令理解和响应。",
    "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": "Llama 3 70B Instruct Turbo 提供卓越的语言理解和生成能力，适合最苛刻的计算任务。",
    "deepseek-r1-distill-llama-8b": "DeepSeek-R1-Distill-Llama-8B是DeepSeek-R1基于Llama3.1-8B-Base的蒸馏模型。",
    "internvl2.5-latest": "我们仍在维护的 InternVL2.5 版本，具备优异且稳定的性能。默认指向我们最新发布的 InternVL2.5 系列模型，当前指向 internvl2.5-78b。",
    "ERNIE-Character-8K": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。",
    "step-2-16k": "支持大规模上下文交互，适合复杂对话场景。",
    "mistralai/mistral-7b-instruct": "Mistral 7B Instruct 是一款兼有速度优化和长上下文支持的高性能行业标准模型。",
    "THUDM/GLM-Z1-Rumination-32B-0414": "GLM-Z1-Rumination-32B-0414 是一个具有沉思能力的深度推理模型（与 OpenAI 的 Deep Research 对标）。与典型的深度思考模型不同，沉思模型采用更长时间的深度思考来解决更开放和复杂的问题。",
    "hunyuan-turbos-20250226": "hunyuan-TurboS pv2.1.2 固定版本预训练底座训练token 数升级；数学/逻辑/代码等思考能力提升；中英文通用体验效果提升，包括文本创作、文本理解、知识问答、闲聊等。",
    "meta.llama3-1-70b-instruct-v1:0": "Meta Llama 3.1 70B Instruct 的更新版，包括扩展的 128K 上下文长度、多语言性和改进的推理能力。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。",
    "ministral-8b-latest": "Ministral 8B 是Mistral的性价比极高的边缘模型。",
    "hunyuan-large": "Hunyuan-large 模型总参数量约 389B，激活参数量约 52B，是当前业界参数规模最大、效果最好的 Transformer 架构的开源 MoE 模型。",
    "gemini-1.5-pro-exp-0801": "Gemini 1.5 Pro 0801 提供出色的多模态处理能力，为应用开发带来更大灵活性。",
    "gemma2-9b-it": "Gemma 2 9B 是一款优化用于特定任务和工具整合的模型。",
    "gemini-2.5-pro-exp-03-25": "Gemini 2.5 Pro Experimental 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。",
    "hunyuan-turbo-vision": "混元新一代视觉语言旗舰大模型，采用全新的混合专家模型（MoE）结构，在图文理解相关的基础识别、内容创作、知识问答、分析推理等能力上相比前一代模型全面提升。",
    "whisper-1": "通用语音识别模型，支持多语言语音识别、语音翻译和语言识别",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": "DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力。",
    "mixtral": "Mixtral 是 Mistral AI 的专家模型，具有开源权重，并在代码生成和语言理解方面提供支持。",
    "step-r1-v-mini": "该模型是拥有强大的图像理解能力的推理大模型，能够处理图像和文字信息，经过深度思考后输出文本生成文本内容。该模型在视觉推理领域表现突出，同时拥有第一梯队的数学、代码、文本推理能力。上下文长度为100k。",
    "accounts/fireworks/models/qwen2p5-72b-instruct": "Qwen2.5 是由 Qwen 团队和阿里云开发的一系列仅解码语言模型，提供 0.5B、1.5B、3B、7B、14B、32B 和 72B 不同参数规模，并包含基础版和指令微调版。",
    "/Qen2-1.5B-Instruct": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
    "gemini-1.0-pro-002": "Gemini 1.0 Pro 002 (Tuning) 提供出色的多模态支持，专注于复杂任务的有效解决。",
    "ERNIE-4.0-8K-Latest": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。",
    "taichu_o1": "taichu_o1是新一代推理大模型，通过多模态交互和强化学习实现类人思维链，支持复杂决策推演，在保持高精度输出的同时展现可模型推理的思维路径，适用于策略分析与深度思考等场景。",
    "SenseChat-Character": "拟人对话标准版模型，8K上下文长度，高响应速度",
    "360gpt-turbo": "360GPT Turbo 提供强大的计算和对话能力，具备出色的语义理解和生成效率，是企业和开发者理想的智能助理解决方案。",
    "qwen-max": "通义千问千亿级别超大规模语言模型，支持中文、英文等不同语言输入，当前通义千问2.5产品版本背后的API模型。",
    "yi-lightning": "最新高性能模型，保证高质量输出同时，推理速度大幅提升。",
    "gpt-4o-2024-08-06": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
    "step-1.5v-mini": "该模型拥有强大的视频理解能力。",
    "command-r-plus-08-2024": "Command R+ 是一个遵循指令的对话模型，在语言任务方面表现出更高的质量、更可靠，并且相比以往模型具有更长的上下文长度。它最适用于复杂的 RAG 工作流和多步工具使用。",
    "Qwen/Qwen2.5-14B-Instruct": "Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
    "deepseek-r1": "DeepSeek-R1 在强化学习（RL）之前引入了冷启动数据，在数学、代码和推理任务上表现可与 OpenAI-o1 相媲美。",
    "openai/gpt-4o-mini": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。",
    "openai/o4-mini": "o4-mini 专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。",
    "qwen/qwen2.5-coder-7b-instruct": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
    "ernie-x1-32k-preview": "文心大模型X1具备更强的理解、规划、反思、进化能力。作为能力更全面的深度思考模型，文心X1兼备准确、创意和文采，在中文知识问答、文学创作、文稿写作、日常对话、逻辑推理、复杂计算及工具调用等方面表现尤为出色。",
    "deepseek/deepseek-r1/community": "DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。",
    "hunyuan-translation-lite": "混元翻译模型支持自然语言对话式翻译；支持中文和英语、日语、法语、葡萄牙语、西班牙语、土耳其语、俄语、阿拉伯语、韩语、意大利语、德语、越南语、马来语、印尼语15种语言互译。",
    "SenseChat-128K": "基础版本模型 (V4)，128K上下文长度，在长文本理解及生成等任务中表现出色",
    "internlm/internlm2_5-20b-chat": "InternLM2.5-20B-Chat 是一个开源的大规模对话模型，基于 InternLM2 架构开发。该模型拥有 200 亿参数，在数学推理方面表现出色，超越了同量级的 Llama3 和 Gemma2-27B 模型。InternLM2.5-20B-Chat 在工具调用能力方面有显著提升，支持从上百个网页收集信息进行分析推理，并具备更强的指令理解、工具选择和结果反思能力。它适用于构建复杂智能体，可进行多轮工具调用以完成复杂任务",
    "mathstral": "MathΣtral 专为科学研究和数学推理设计，提供有效的计算能力和结果解释。",
    "moonshot-v1-32k": "Moonshot V1 32K 提供中等长度的上下文处理能力，能够处理32,768个tokens，特别适合生成各种长文档和复杂对话，应用于内容创作、报告生成和对话系统等领域。",
    "360gpt2-pro": "360GPT2 Pro 是 360 公司推出的高级自然语言处理模型，具备卓越的文本生成和理解能力，尤其在生成与创作领域表现出色，能够处理复杂的语言转换和角色演绎任务。",
    "anthropic.claude-3-sonnet-20240229-v1:0": "Anthropic 的 Claude 3 Sonnet 在智能和速度之间达到了理想的平衡——特别适合企业工作负载。它以低于竞争对手的价格提供最大的效用，并被设计成为可靠的、高耐用的主力机，适用于规模化的 AI 部署。Claude 3 Sonnet 可以处理图像并返回文本输出，具有 200K 的上下文窗口。"
    }
   }
}